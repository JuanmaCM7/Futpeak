{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c12f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Directorio de trabajo actual: F:\\JCMDataCenter\\Cursos\\Evolve Academy\\Data Scientist IA\\Futpeak\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Establece la raÃ­z del proyecto manualmente\n",
    "project_root = Path(\"F:/JCMDataCenter/Cursos/Evolve Academy/Data Scientist IA/Futpeak\") # sobremesa\n",
    "#project_root = Path(\"C:/Users/juanm/Desktop/FUTPEAK/Futpeak\") # portÃ¡til\n",
    "\n",
    "# Cambia el directorio de trabajo actual a esa raÃ­z\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"ðŸ“ Directorio de trabajo actual:\", Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637ed5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 1 completed â†’ Basic metadata saved at: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# Processing de metadata\n",
    "\n",
    "# Crear csv con id y player name\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths\n",
    "input_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "output_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lines = []\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f if \"fbref.com\" in line]\n",
    "\n",
    "records = []\n",
    "\n",
    "for line in lines:\n",
    "    try:\n",
    "        # === 1. Player ID and Slug\n",
    "        url_match = re.search(r\"https://fbref\\.com/en/players/([a-f0-9]{8})/([^\\s/,]+)\", line)\n",
    "        if not url_match:\n",
    "            continue\n",
    "        player_id = url_match.group(1)\n",
    "        slug = url_match.group(2)\n",
    "        player_name = slug.replace(\"_\", \" \").title()\n",
    "        url_template = url_match.group(0)\n",
    "\n",
    "        # === 2. Full name (text after ID, before next comma)\n",
    "        name_match = re.search(rf\"{player_id},([^,]+)\", line)\n",
    "        full_name = name_match.group(1).strip() if name_match else None\n",
    "\n",
    "        records.append({\n",
    "            \"Player_ID\": player_id,\n",
    "            \"Player_name\": player_name,\n",
    "            \"Full_name\": full_name,\n",
    "            \"Url_template\": url_template\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error on line:\\n{line}\\nâ†’ {e}\")\n",
    "\n",
    "# === Save output\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Step 1 completed â†’ Basic metadata saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855b1165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 2 completado â†’ Full_name actualizado en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 2\n",
    "# AÃ±adir full name vÃ¡lido desde raw y corregir player_name\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para nombres con 3 o mÃ¡s palabras capitalizadas\n",
    "name_pattern = re.compile(\n",
    "    r\"\\b([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±'â€™\\-]+(?:\\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±'â€™\\-]+){2,})\\b\"\n",
    ")\n",
    "\n",
    "# === Extraer full names desde raw comparando contra player_name\n",
    "clean_full_names = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    player_name = row[\"Player_name\"]\n",
    "\n",
    "    # Buscar lÃ­nea que contenga el ID del jugador\n",
    "    matching_line = next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")\n",
    "\n",
    "    # Buscar candidato a nombre completo\n",
    "    match = name_pattern.search(matching_line)\n",
    "    candidate = match.group(1) if match else \"\"\n",
    "\n",
    "    player_tokens = player_name.replace(\"-\", \" \").title().split()\n",
    "    full_tokens = candidate.split()\n",
    "\n",
    "    # Validar que al menos 2 palabras coincidan\n",
    "    common = set(p.lower() for p in player_tokens) & set(f.lower() for f in full_tokens)\n",
    "    if candidate and len(common) >= 2:\n",
    "        clean_full_names.append(candidate)\n",
    "    else:\n",
    "        clean_full_names.append(\"\")\n",
    "\n",
    "# === Corregir player_name (sin guiones, capitalizado)\n",
    "df[\"Player_name\"] = df[\"Player_name\"].astype(str).str.replace(\"-\", \" \", regex=False).str.title()\n",
    "\n",
    "# === Insertar nombres completos validados\n",
    "df[\"Full_name\"] = clean_full_names\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 2 completado â†’ Full_name actualizado en: {cleaned_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7cffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 3 completado â†’ Birth_date aÃ±adido a: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 3\n",
    "# AÃ±adir fecha de nacimiento\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para fechas en formato YYYY-MM-DD\n",
    "date_pattern = re.compile(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\")\n",
    "\n",
    "# === Buscar fecha de nacimiento para cada jugador en raw_lines\n",
    "birth_dates = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "    \n",
    "    # Buscar la lÃ­nea que contiene este ID\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    match = date_pattern.search(matching_line)\n",
    "    birth_date = match.group(0) if match else \"\"\n",
    "    birth_dates.append(birth_date)\n",
    "\n",
    "# === AÃ±adir columna al DataFrame\n",
    "df[\"Birth_date\"] = birth_dates\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 3 completado â†’ Birth_date aÃ±adido a: {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9922b576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 4 completado â†’ Age aÃ±adido a: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 4\n",
    "# AÃ±adir edad (Age)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para edad en formato NN-NNN\n",
    "age_pattern = re.compile(r\"\\b\\d{2}-\\d{3}\\b\")\n",
    "\n",
    "# === Buscar edad para cada jugador en raw_lines\n",
    "ages = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "    \n",
    "    # Buscar lÃ­nea que contiene el ID\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    match = age_pattern.search(matching_line)\n",
    "    age = match.group(0) if match else \"\"\n",
    "    ages.append(age)\n",
    "\n",
    "# === AÃ±adir columna al DataFrame\n",
    "df[\"Age\"] = ages\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 4 completado â†’ Age aÃ±adido a: {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cf5ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 5 completado â†’ Position aÃ±adido correctamente a: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 5\n",
    "# AÃ±adir posiciÃ³n (Position)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load existing cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para extraer etiquetas en mayÃºsculas (ej. DF, MF, CB, etc.)\n",
    "position_pattern = re.compile(r\"\\b([A-Z]{2,})\\b\")\n",
    "\n",
    "positions = []\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar lÃ­nea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    matches = position_pattern.findall(matching_line)\n",
    "\n",
    "    # Filtrar posibles valores vÃ¡lidos (puedes ajustar lÃ³gica aquÃ­ si hace falta)\n",
    "    valid = sorted(set(m for m in matches if len(m) >= 2))\n",
    "    \n",
    "    positions.append(\"-\".join(valid) if valid else \"\")\n",
    "\n",
    "# === AÃ±adir al DataFrame\n",
    "df[\"Position\"] = positions\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 5 completado â†’ Position aÃ±adido correctamente a: {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07791581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 6 completado â†’ Footed aÃ±adido correctamente en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 6\n",
    "# AÃ±adir pierna dominante (Footed)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load current cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para detectar pierna dominante\n",
    "footed_pattern = re.compile(r\"\\b(Right|Left)\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "footed_values = []\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar la lÃ­nea que contiene el ID del jugador\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "\n",
    "    match = footed_pattern.search(matching_line)\n",
    "    footed = match.group(1).capitalize() if match else \"\"\n",
    "    footed_values.append(footed)\n",
    "\n",
    "# === AÃ±adir columna Footed\n",
    "df[\"Footed\"] = footed_values\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 6 completado â†’ Footed aÃ±adido correctamente en: {cleaned_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76edbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 7 completado â†’ Birth_place aÃ±adido correctamente en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 7\n",
    "# AÃ±adir lugar de nacimiento (Birth_place)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned CSV\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw metadata lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para extraer 'in City, Country'\n",
    "birthplace_pattern = re.compile(r'\"in ([^\"]+,[^\"]+)\"')\n",
    "\n",
    "birth_places = []\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar lÃ­nea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "\n",
    "    match = birthplace_pattern.search(matching_line)\n",
    "    place = match.group(1).strip() if match else \"\"\n",
    "    birth_places.append(place)\n",
    "\n",
    "# === AÃ±adir al DataFrame\n",
    "df[\"Birth_place\"] = birth_places\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 7 completado â†’ Birth_place aÃ±adido correctamente en: {cleaned_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69dd5f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 8 completado â†’ Nationality aÃ±adida correctamente en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 8\n",
    "# AÃ±adir nacionalidad (Nationality)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths\n",
    "metadata_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "teams_path = Path(\"data/meta/World_Cup_Qualification_Teams.csv\")\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "\n",
    "# === Load data\n",
    "df = pd.read_csv(metadata_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "teams_df = pd.read_csv(teams_path, dtype=str, encoding=\"utf-8\")\n",
    "\n",
    "# === Lista de paÃ­ses vÃ¡lidos\n",
    "country_names = set(teams_df[\"National Team\"].dropna().str.strip())\n",
    "\n",
    "# === Leer las lÃ­neas originales (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = [line.strip() for line in f.readlines()][1:]\n",
    "\n",
    "# === Buscar paÃ­s para cada jugador\n",
    "nationalities = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar lÃ­nea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    found = next((country for country in country_names if country in matching_line), \"\")\n",
    "    nationalities.append(found)\n",
    "\n",
    "# === Asignar columna y guardar\n",
    "df[\"Nationality\"] = nationalities\n",
    "df.to_csv(metadata_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 8 completado â†’ Nationality aÃ±adida correctamente en: {metadata_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a904ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 9 completado â†’ Full_name corregido y Club aÃ±adido en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 9\n",
    "# AÃ±adir club (Club) y corregir Full_name con control total\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "df_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Cargar DataFrame existente\n",
    "df = pd.read_csv(df_path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Cargar lÃ­neas crudas\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para Full_name con 3+ palabras capitalizadas\n",
    "name_regex = re.compile(\n",
    "    r\"\\b([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼']+(?:\\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼']+){2,})\\b\"\n",
    ")\n",
    "\n",
    "# === Procesamiento\n",
    "clean_full_names = []\n",
    "clubs = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar lÃ­nea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "\n",
    "    # === Step 1: Full name limpio\n",
    "    name_match = name_regex.search(matching_line)\n",
    "    clean_name = name_match.group(1) if name_match else \"\"\n",
    "    clean_full_names.append(clean_name)\n",
    "\n",
    "    # === Step 2: Club\n",
    "    parts = [p.strip() for p in matching_line.split(\",\") if p.strip()]\n",
    "\n",
    "    known_vals = {\n",
    "        row[\"Player_name\"].lower(),\n",
    "        clean_name.lower(),\n",
    "        row[\"Player_ID\"].lower(),\n",
    "        row[\"Footed\"].lower(),\n",
    "        row[\"Birth_date\"].lower(),\n",
    "        row[\"Age\"].lower(),\n",
    "        row[\"Birth_place\"].lower(),\n",
    "        row[\"Nationality\"].lower(),\n",
    "    }\n",
    "\n",
    "    best_candidate = \"\"\n",
    "    for part in parts:\n",
    "        pl = part.lower()\n",
    "\n",
    "        if (\n",
    "            not part\n",
    "            or \"http\" in pl\n",
    "            or \"footed\" in pl\n",
    "            or \"position\" in pl\n",
    "            or \"in \" in pl\n",
    "            or re.fullmatch(r\"[a-f0-9]{8}\", pl)\n",
    "            or re.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}\", pl)\n",
    "            or re.fullmatch(r\"\\d{2}-\\d{3}\", pl)\n",
    "            or pl in known_vals\n",
    "            or re.fullmatch(r\"[A-Z]{1,3}(-[A-Z]{1,3})+\", part)  # Ej: CM-DM\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Buscar candidato mÃ¡s probable\n",
    "        if re.fullmatch(r\"[A-Z][a-z]+(?: [A-Z][a-z]+)*\", part) and len(part) > len(best_candidate):\n",
    "            best_candidate = part\n",
    "\n",
    "    clubs.append(best_candidate)\n",
    "\n",
    "# === Asignar columnas finales\n",
    "df[\"Full_name\"] = clean_full_names\n",
    "df[\"Club\"] = clubs\n",
    "\n",
    "# === Guardar archivo actualizado\n",
    "df.to_csv(df_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 9 completado â†’ Full_name corregido y Club aÃ±adido en: {df_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99110f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paso 10 completado â†’ Clubs corregidos en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 10\n",
    "# Segunda pasada para refinar Club\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "df_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Cargar DataFrame y raw lines\n",
    "df = pd.read_csv(df_path, dtype=str).fillna(\"\")\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "clubs_fixed = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar lÃ­nea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\").strip().replace('\"', '')\n",
    "    parts = [p.strip() for p in matching_line.split(\",\") if p.strip()]\n",
    "\n",
    "    # Valores ya conocidos para este jugador\n",
    "    known = {\n",
    "        row[\"Player_name\"].lower(),\n",
    "        row[\"Full_name\"].lower(),\n",
    "        row[\"Footed\"].lower(),\n",
    "        row[\"Birth_date\"].lower(),\n",
    "        row[\"Age\"].lower(),\n",
    "        row[\"Birth_place\"].lower(),\n",
    "        row[\"Nationality\"].lower(),\n",
    "        row[\"Position\"].lower(),\n",
    "    }\n",
    "\n",
    "    # Buscar mejor candidato a club\n",
    "    best = \"\"\n",
    "    for p in parts:\n",
    "        pl = p.lower()\n",
    "        if (\n",
    "            not p\n",
    "            or \"http\" in pl\n",
    "            or pl in known\n",
    "            or any(x in pl for x in [\"position\", \"footed\", \"in \"])\n",
    "            or len(p) < 2\n",
    "            or p.isupper()\n",
    "            or p.replace(\"-\", \"\").isupper()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        if p[0].isupper():\n",
    "            best = p  # Ãºltima candidata vÃ¡lida\n",
    "\n",
    "    clubs_fixed.append(best)\n",
    "\n",
    "df[\"Club\"] = clubs_fixed\n",
    "\n",
    "# === Guardar CSV final con Club corregido\n",
    "df.to_csv(df_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Paso 10 completado â†’ Clubs corregidos en: {df_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8922f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GÃ©nero inferido automÃ¡ticamente y guardado en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Inferir gÃ©nero usando gender-guesser\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "# === Paths\n",
    "csv_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Crear detector\n",
    "detector = gender.Detector(case_sensitive=False)\n",
    "\n",
    "# === Extraer primer nombre\n",
    "df[\"First_name\"] = df[\"Player_name\"].str.strip().str.split().str[0]\n",
    "\n",
    "# === Inferir gÃ©nero usando la librerÃ­a\n",
    "def normalize_gender(name):\n",
    "    try:\n",
    "        raw = detector.get_gender(name)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "    if raw in [\"male\", \"mostly_male\"]:\n",
    "        return \"male\"\n",
    "    elif raw in [\"female\", \"mostly_female\"]:\n",
    "        return \"female\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"Gender\"] = df[\"First_name\"].apply(normalize_gender)\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… GÃ©nero inferido automÃ¡ticamente y guardado en: {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e993fbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Recuento por gÃ©nero:\n",
      "Gender\n",
      "male       14547\n",
      "unknown     2104\n",
      "female       876\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ‘€ Ejemplos de jugadores con gÃ©nero 'unknown':\n",
      "                    Full_name First_name  \\\n",
      "26                             Lisandro   \n",
      "42                              Joaquin   \n",
      "43        Yamil Rodrigo Asad      Yamil   \n",
      "59   Cristian Nahuel Barrios     Nahuel   \n",
      "101                              Nahuel   \n",
      "151                             Lautaro   \n",
      "157    Carlos JoaquÃ­n Correa    Joaquin   \n",
      "170                              Braian   \n",
      "172  HernÃ¡n NicolÃ¡s Da Campo     Hernan   \n",
      "236       Luis Yamil Garnier      Yamil   \n",
      "\n",
      "                                       Club  \n",
      "26                                LDU Quito  \n",
      "42                                           \n",
      "43                                   CuiabÃ¡  \n",
      "59                         Barracas Central  \n",
      "101                                Talleres  \n",
      "151                        Sportivo Luqueno  \n",
      "157                          Internazionale  \n",
      "170  Central CÃ³rdoba de Santiago del Estero  \n",
      "172                              Sport Boys  \n",
      "236                                          \n"
     ]
    }
   ],
   "source": [
    "# === Ver resumen de gÃ©nero\n",
    "print(\"ðŸ” Recuento por gÃ©nero:\")\n",
    "print(df[\"Gender\"].value_counts(dropna=False))\n",
    "print(\"\\nðŸ‘€ Ejemplos de jugadores con gÃ©nero 'unknown':\\n\", df[df[\"Gender\"] == \"unknown\"][[\"Full_name\", \"First_name\", \"Club\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db7a066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Yamil Rodrigo Asad â†’ male\n",
      "âš ï¸ Error con Cristian Nahuel Barrios: Message: invalid session id: session deleted as the browser has closed the connection\n",
      "from disconnected: not connected to DevTools\n",
      "  (Session info: chrome=136.0.7103.114)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00B7FC83+61635]\n",
      "\tGetHandleVerifier [0x00B7FCC4+61700]\n",
      "\t(No symbol) [0x009A05D3]\n",
      "\t(No symbol) [0x0098FE20]\n",
      "\t(No symbol) [0x009ADD1F]\n",
      "\t(No symbol) [0x00A13E8C]\n",
      "\t(No symbol) [0x00A2DF19]\n",
      "\t(No symbol) [0x00A0D096]\n",
      "\t(No symbol) [0x009DC840]\n",
      "\t(No symbol) [0x009DD6A4]\n",
      "\tGetHandleVerifier [0x00E045A3+2701795]\n",
      "\tGetHandleVerifier [0x00DFFD26+2683238]\n",
      "\tGetHandleVerifier [0x00E1AA6E+2793134]\n",
      "\tGetHandleVerifier [0x00B96945+155013]\n",
      "\tGetHandleVerifier [0x00B9D02D+181357]\n",
      "\tGetHandleVerifier [0x00B874D8+92440]\n",
      "\tGetHandleVerifier [0x00B87680+92864]\n",
      "\tGetHandleVerifier [0x00B72070+5296]\n",
      "\tBaseThreadInitThunk [0x74CD5D49+25]\n",
      "\tRtlInitializeExceptionChain [0x76FED03B+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x76FECFC1+561]\n",
      "\n",
      "âœ… Cristian Nahuel Barrios â†’ unknown\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m â†’ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgender\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ Error general con \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# === Cargar dataset\n",
    "csv_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Configurar navegador\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# === Asegurar columna Gender\n",
    "if \"Gender\" not in df.columns:\n",
    "    df[\"Gender\"] = \"unknown\"\n",
    "\n",
    "# === FunciÃ³n de detecciÃ³n con Bing + mÃºltiples bloques\n",
    "def infer_gender_bing(full_name):\n",
    "    try:\n",
    "        query = f\"{full_name} futbolista\"\n",
    "        bing_url = f\"https://www.bing.com/search?q={query.replace(' ', '+')}\"\n",
    "        driver.get(bing_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        snippets = []\n",
    "\n",
    "        # Seleccionamos mÃºltiples bloques relevantes\n",
    "        selectors = [\n",
    "            \"div.b_entityTP\",  # panel destacado\n",
    "            \"div.b_context\",\n",
    "            \"div.b_caption\",\n",
    "            \"div.b_algo\",\n",
    "            \"div.b_snippet\",\n",
    "        ]\n",
    "\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                el = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                snippets.append(el.text.lower())\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        full_text = \" \".join(snippets)\n",
    "\n",
    "        if \"es una futbolista\" in full_text:\n",
    "            return \"female\"\n",
    "        elif \"es un futbolista\" in full_text:\n",
    "            return \"male\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error con {full_name}: {e}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "# === Iterar por unknowns\n",
    "for i, row in df[df[\"Gender\"] == \"unknown\"].iterrows():\n",
    "    full_name = row[\"Full_name\"]\n",
    "    if not isinstance(full_name, str) or not full_name.strip():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        gender = infer_gender_bing(full_name)\n",
    "        df.at[i, \"Gender\"] = gender\n",
    "        print(f\"âœ… {full_name} â†’ {gender}\")\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "        time.sleep(1.5)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error general con {full_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "print(\"ðŸŽ¯ Completado. GÃ©neros actualizados en el CSV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250bed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Final cleaned CSV saved at: data\\processed\\cleaned_matchlogs.csv | Rows: 1947093\n"
     ]
    }
   ],
   "source": [
    "# Processing completo y final\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === File paths\n",
    "input_path = Path(\"data/raw/top_10_countries_matchlogs_filtered.csv\")\n",
    "output_path = Path(\"data/processed/cleaned_matchlogs.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Step 1: Load raw CSV\n",
    "df = pd.read_csv(input_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Step 2: Normalize player_name formatting\n",
    "df[\"player_name\"] = df[\"player_name\"].str.replace(\"_\", \" \", regex=False).str.title()\n",
    "\n",
    "# === Step 3: Rename columns\n",
    "rename_dict = {\n",
    "    \"player_name\": \"Player_name\",\n",
    "    \"player_id\": \"Player_ID\",\n",
    "    \"season\": \"Seasons\",\n",
    "    \"Date\": \"Date\", \"Day\": \"Day\", \"Comp\": \"Competition\", \"Round\": \"Round\", \"Venue\": \"Home_Away\",\n",
    "    \"Result\": \"Result\", \"Squad\": \"Player_team\", \"Opponent\": \"Rival_team\", \"Start\": \"Start\",\n",
    "    \"Pos\": \"Position\", \"Min\": \"Minutes\", \"Gls\": \"Goals\", \"Ast\": \"Assists\", \"PK\": \"Penalty_kick\",\n",
    "    \"PKatt\": \"Penalty_kick_att\", \"Sh\": \"Shots\", \"SoT\": \"Shots_on_target\", \"CrdY\": \"Yellow_cards\",\n",
    "    \"CrdR\": \"Red_cards\", \"Fls\": \"Fouls_committed\", \"Fld\": \"Fouls_drawn\", \"Off\": \"Offsides\",\n",
    "    \"Crs\": \"Crosses\", \"TklW\": \"Tackles_won\", \"Int\": \"Interceptions\", \"OG\": \"Own_goals\",\n",
    "    \"PKwon\": \"Penaltys_won\", \"PKcon\": \"Penaltys_conceded\", \"Touches\": \"Touches\", \"Tkl\": \"Tackles\",\n",
    "    \"Blocks\": \"Blocks\", \"xG\": \"xG\", \"npxG\": \"non_penalty_xG\", \"xAG\": \"x_assisted_G\",\n",
    "    \"SCA\": \"Shot_creating_actions\", \"GCA\": \"Goal_creating_actions\", \"Cmp\": \"Passes_completed\",\n",
    "    \"Att\": \"Passes_att\", \"Cmp%\": \"Percent_passes\", \"PrgP\": \"Progressive_passes\",\n",
    "    \"Carries\": \"Feet_control\", \"PrgC\": \"Progressive_control\", \"Succ\": \"Dribling_suc\"\n",
    "}\n",
    "df.rename(columns={k: v for k, v in rename_dict.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# === Step 4: Remove unwanted columns\n",
    "for col in [\"Match Report\", \"season\", \"player_name\", \"player_id\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# === Step 5: Clean rows (required fields must be present)\n",
    "df = df[df[\"Player_name\"].notna() & df[\"Player_ID\"].notna() & df[\"Seasons\"].notna()]\n",
    "if \"Date\" in df.columns:\n",
    "    df = df[df[\"Date\"].notna()]\n",
    "\n",
    "# === Step 6: Remove rows where the player didnâ€™t play\n",
    "if \"Position\" in df.columns:\n",
    "    df = df[df[\"Position\"] != \"On matchday squad, but did not play\"]\n",
    "\n",
    "# âœ… Step 6.5: Drop rows where all values are empty (except core fields)\n",
    "non_core = [col for col in df.columns if col not in [\"Player_name\", \"Player_ID\", \"Seasons\"]]\n",
    "df = df[df[non_core].apply(lambda row: any(cell.strip() for cell in row), axis=1)]\n",
    "\n",
    "# === Step 7: Remove duplicate games (player_id + date)\n",
    "if \"Date\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"Player_ID\", \"Date\"])\n",
    "\n",
    "# === Step 8: Clean up team names by removing country codes\n",
    "for col in [\"Player_team\", \"Rival_team\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.replace(r\"^[a-z]{2,3}\\s+\", \"\", regex=True)\n",
    "\n",
    "# === Step 9: Reorder columns\n",
    "core = [\"Player_name\", \"Player_ID\", \"Seasons\"]\n",
    "rest = [c for c in df.columns if c not in core]\n",
    "df = df[core + rest]\n",
    "\n",
    "# === Step 10: Save\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"ðŸŽ¯ Final cleaned CSV saved at: {output_path} | Rows: {len(df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Final cleaned CSV saved at: data\\processed\\future_stars_cleaned_matchlogs.csv | Rows: 1053\n"
     ]
    }
   ],
   "source": [
    "# Processing completo y final JUGADORES JÃ“VENES\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === File paths\n",
    "input_path = Path(\"data/raw/top_10_countries_matchlogs_young_players.csv\")\n",
    "output_path = Path(\"data/processed/future_stars_cleaned_matchlogs.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Step 1: Load raw CSV\n",
    "df = pd.read_csv(input_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Step 2: Normalize player_name formatting\n",
    "df[\"player_name\"] = df[\"player_name\"].str.replace(\"_\", \" \", regex=False).str.title()\n",
    "\n",
    "# === Step 3: Rename columns\n",
    "rename_dict = {\n",
    "    \"player_name\": \"Player_name\",\n",
    "    \"player_id\": \"Player_ID\",\n",
    "    \"season\": \"Seasons\",\n",
    "    \"Date\": \"Date\", \"Day\": \"Day\", \"Comp\": \"Competition\", \"Round\": \"Round\", \"Venue\": \"Home_Away\",\n",
    "    \"Result\": \"Result\", \"Squad\": \"Player_team\", \"Opponent\": \"Rival_team\", \"Start\": \"Start\",\n",
    "    \"Pos\": \"Position\", \"Min\": \"Minutes\", \"Gls\": \"Goals\", \"Ast\": \"Assists\", \"PK\": \"Penalty_kick\",\n",
    "    \"PKatt\": \"Penalty_kick_att\", \"Sh\": \"Shots\", \"SoT\": \"Shots_on_target\", \"CrdY\": \"Yellow_cards\",\n",
    "    \"CrdR\": \"Red_cards\", \"Fls\": \"Fouls_committed\", \"Fld\": \"Fouls_drawn\", \"Off\": \"Offsides\",\n",
    "    \"Crs\": \"Crosses\", \"TklW\": \"Tackles_won\", \"Int\": \"Interceptions\", \"OG\": \"Own_goals\",\n",
    "    \"PKwon\": \"Penaltys_won\", \"PKcon\": \"Penaltys_conceded\", \"Touches\": \"Touches\", \"Tkl\": \"Tackles\",\n",
    "    \"Blocks\": \"Blocks\", \"xG\": \"xG\", \"npxG\": \"non_penalty_xG\", \"xAG\": \"x_assisted_G\",\n",
    "    \"SCA\": \"Shot_creating_actions\", \"GCA\": \"Goal_creating_actions\", \"Cmp\": \"Passes_completed\",\n",
    "    \"Att\": \"Passes_att\", \"Cmp%\": \"Percent_passes\", \"PrgP\": \"Progressive_passes\",\n",
    "    \"Carries\": \"Feet_control\", \"PrgC\": \"Progressive_control\", \"Succ\": \"Dribling_suc\"\n",
    "}\n",
    "df.rename(columns={k: v for k, v in rename_dict.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# === Step 4: Remove unwanted columns\n",
    "for col in [\"Match Report\", \"season\", \"player_name\", \"player_id\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# === Step 5: Clean rows (required fields must be present)\n",
    "df = df[df[\"Player_name\"].notna() & df[\"Player_ID\"].notna() & df[\"Seasons\"].notna()]\n",
    "if \"Date\" in df.columns:\n",
    "    df = df[df[\"Date\"].notna()]\n",
    "\n",
    "# === Step 6: Remove rows where the player didnâ€™t play\n",
    "if \"Position\" in df.columns:\n",
    "    df = df[df[\"Position\"] != \"On matchday squad, but did not play\"]\n",
    "\n",
    "# âœ… Step 6.5: Drop rows where all values are empty (except core fields)\n",
    "non_core = [col for col in df.columns if col not in [\"Player_name\", \"Player_ID\", \"Seasons\"]]\n",
    "df = df[df[non_core].apply(lambda row: any(cell.strip() for cell in row), axis=1)]\n",
    "\n",
    "# === Step 7: Remove duplicate games (player_id + date)\n",
    "if \"Date\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"Player_ID\", \"Date\"])\n",
    "\n",
    "# === Step 8: Clean up team names by removing country codes\n",
    "for col in [\"Player_team\", \"Rival_team\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.replace(r\"^[a-z]{2,3}\\s+\", \"\", regex=True)\n",
    "\n",
    "# === Step 9: Reorder columns\n",
    "core = [\"Player_name\", \"Player_ID\", \"Seasons\"]\n",
    "rest = [c for c in df.columns if c not in core]\n",
    "df = df[core + rest]\n",
    "\n",
    "# === Step 10: Save\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"ðŸŽ¯ Final cleaned CSV saved at: {output_path} | Rows: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed44c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_metadata_file(raw_path: Path, cleaned_path: Path, teams_path: Path = Path(\"data/meta/World_Cup_Qualification_Teams.csv\")):\n",
    "    raw_lines = [line.strip() for line in raw_path.read_text(encoding=\"utf-8\").splitlines()[1:]]\n",
    "\n",
    "    # === Paso 1: ID, slug, nombre base\n",
    "    records = []\n",
    "    for line in raw_lines:\n",
    "        url_match = re.search(r\"https://fbref\\.com/en/players/([a-f0-9]{8})/([^\\s/,]+)\", line)\n",
    "        if not url_match:\n",
    "            continue\n",
    "        player_id = url_match.group(1)\n",
    "        slug = url_match.group(2)\n",
    "        player_name = slug.replace(\"_\", \" \").title()\n",
    "        url_template = url_match.group(0)\n",
    "\n",
    "        name_match = re.search(rf\"{player_id},([^,]+)\", line)\n",
    "        full_name = name_match.group(1).strip() if name_match else \"\"\n",
    "\n",
    "        records.append({\n",
    "            \"Player_ID\": player_id,\n",
    "            \"Player_name\": player_name,\n",
    "            \"Full_name\": full_name,\n",
    "            \"Url_template\": url_template\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records).fillna(\"\")\n",
    "\n",
    "    # === Paso 2: Validar Full_name\n",
    "    name_pattern = re.compile(r\"\\b([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼'â€™\\-]+(?:\\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼'â€™\\-]+){2,})\\b\")\n",
    "    clean_full_names = []\n",
    "    for _, row in df.iterrows():\n",
    "        match_line = next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")\n",
    "        match = name_pattern.search(match_line)\n",
    "        candidate = match.group(1) if match else \"\"\n",
    "\n",
    "        player_tokens = row[\"Player_name\"].replace(\"-\", \" \").title().split()\n",
    "        full_tokens = candidate.split()\n",
    "        common = set(p.lower() for p in player_tokens) & set(f.lower() for f in full_tokens)\n",
    "\n",
    "        clean_full_names.append(candidate if candidate and len(common) >= 2 else \"\")\n",
    "    df[\"Player_name\"] = df[\"Player_name\"].str.replace(\"-\", \" \", regex=False).str.title()\n",
    "    df[\"Full_name\"] = clean_full_names\n",
    "\n",
    "    # === Paso 3: Birth_date\n",
    "    date_pattern = re.compile(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\")\n",
    "    df[\"Birth_date\"] = [\n",
    "        date_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")).group(0)\n",
    "        if date_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 4: Age\n",
    "    age_pattern = re.compile(r\"\\b\\d{2}-\\d{3}\\b\")\n",
    "    df[\"Age\"] = [\n",
    "        age_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")).group(0)\n",
    "        if age_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 5: Position\n",
    "    pos_pattern = re.compile(r\"\\b([A-Z]{2,})\\b\")\n",
    "    df[\"Position\"] = [\n",
    "        \"-\".join(sorted(set(m for m in pos_pattern.findall(\n",
    "            next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")\n",
    "        ) if len(m) >= 2))) or \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 6: Footed\n",
    "    footed_pattern = re.compile(r\"\\b(Right|Left)\\b\", flags=re.IGNORECASE)\n",
    "    df[\"Footed\"] = [\n",
    "        (footed_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) or re.match(\"\", \"\")).group(0).capitalize()\n",
    "        if footed_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 7: Birth_place\n",
    "    birth_place_pattern = re.compile(r'\"in ([^\"]+,[^\"]+)\"')\n",
    "    df[\"Birth_place\"] = [\n",
    "        birth_place_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")).group(1).strip()\n",
    "        if birth_place_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 8: Nationality\n",
    "    teams_df = pd.read_csv(teams_path, dtype=str)\n",
    "    countries = set(teams_df[\"National Team\"].dropna().str.strip())\n",
    "\n",
    "    df[\"Nationality\"] = [\n",
    "        next((country for country in countries if country in next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")), \"\")\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 9-10: Club (refinado)\n",
    "    clubs = []\n",
    "    for _, row in df.iterrows():\n",
    "        line = next((l for l in raw_lines if row[\"Player_ID\"] in l), \"\").replace('\"', '')\n",
    "        parts = [p.strip() for p in line.split(\",\") if p.strip()]\n",
    "        known = {str(row[k]).lower() for k in [\"Player_name\", \"Full_name\", \"Footed\", \"Birth_date\", \"Age\", \"Birth_place\", \"Nationality\", \"Position\"]}\n",
    "        best = \"\"\n",
    "        for p in parts:\n",
    "            pl = p.lower()\n",
    "            if (\n",
    "                not p or \"http\" in pl or pl in known or len(p) < 2 or\n",
    "                \"position\" in pl or \"footed\" in pl or \"in \" in pl or\n",
    "                p.isupper() or p.replace(\"-\", \"\").isupper()\n",
    "            ):\n",
    "                continue\n",
    "            if p[0].isupper():\n",
    "                best = p\n",
    "        clubs.append(best)\n",
    "    df[\"Club\"] = clubs\n",
    "\n",
    "    # === Paso FINAL: Asignar Gender = male\n",
    "    df[\"Gender\"] = \"male\"\n",
    "\n",
    "    # === Guardar CSV final\n",
    "    cleaned_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"âœ… Metadata procesada y guardada en: {cleaned_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14976380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metadata procesada y guardada en: data\\processed\\future_stars_cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "raw_path = Path(\"data/raw/future_stars_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/future_stars_cleaned_metadata.csv\")\n",
    "\n",
    "df_cleaned = process_metadata_file(raw_path, cleaned_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c24956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Marcos AcuÃ±a (ID: 81442ecb)\n",
      "   Total matches played: 431\n",
      "   âž¤ With Argentina: 59\n",
      "   âž¤ With Clubs: 372\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Load cleaned matchlogs\n",
    "path = Path(\"data/processed/cleaned_matchlogs.csv\")\n",
    "df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Filtrar por jugador\n",
    "player_id = \"81442ecb\"\n",
    "df_acuna = df[df[\"Player_ID\"] == player_id].copy()\n",
    "\n",
    "# === Filtrar partidos jugados (Min > 0)\n",
    "df_acuna[\"Minutes\"] = pd.to_numeric(df_acuna[\"Minutes\"], errors=\"coerce\").fillna(0)\n",
    "df_played = df_acuna[df_acuna[\"Minutes\"] > 0]\n",
    "\n",
    "# === Contar\n",
    "total_matches = len(df_played)\n",
    "national_team_matches = len(df_played[df_played[\"Player_team\"] == \"Argentina\"])\n",
    "club_matches = total_matches - national_team_matches\n",
    "\n",
    "print(f\"ðŸŽ¯ Marcos AcuÃ±a (ID: {player_id})\")\n",
    "print(f\"   Total matches played: {total_matches}\")\n",
    "print(f\"   âž¤ With Argentina: {national_team_matches}\")\n",
    "print(f\"   âž¤ With Clubs: {club_matches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f96c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš½ Marcos AcuÃ±a (ID 81442ecb) â†’ Goals: 30 | Assists: 57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Load cleaned matchlogs\n",
    "path = Path(\"data/processed/cleaned_matchlogs.csv\")\n",
    "df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Filtrar por Player_ID\n",
    "player_id = \"81442ecb\"\n",
    "df_acuna = df[df[\"Player_ID\"] == player_id].copy()\n",
    "\n",
    "# Convertir columnas numÃ©ricas\n",
    "df_acuna[\"Goals\"] = pd.to_numeric(df_acuna[\"Goals\"], errors=\"coerce\").fillna(0)\n",
    "df_acuna[\"Assists\"] = pd.to_numeric(df_acuna[\"Assists\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# === Calcular totales\n",
    "total_goals = int(df_acuna[\"Goals\"].sum())\n",
    "total_assists = int(df_acuna[\"Assists\"].sum())\n",
    "\n",
    "print(f\"âš½ Marcos AcuÃ±a (ID {player_id}) â†’ Goals: {total_goals} | Assists: {total_assists}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72f1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš½ Kylian MbappÃ© (ID 42fd9c7f) â†’ Goals: 0 | Assists: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV limpio\n",
    "df = pd.read_csv(\"data/processed/cleaned_matchlogs.csv\")\n",
    "\n",
    "# === Filtrar por Player_ID\n",
    "player_id = \"42fd9c7f\"\n",
    "df_mbappe = df[df[\"Player_ID\"] == player_id].copy()\n",
    "\n",
    "# Convertir columnas numÃ©ricas\n",
    "df_mbappe[\"Goals\"] = pd.to_numeric(df_mbappe[\"Goals\"], errors=\"coerce\").fillna(0)\n",
    "df_mbappe[\"Assists\"] = pd.to_numeric(df_mbappe[\"Assists\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# === Calcular totales\n",
    "total_goals = int(df_mbappe[\"Goals\"].sum())\n",
    "total_assists = int(df_mbappe[\"Assists\"].sum())\n",
    "\n",
    "\n",
    "print(f\"âš½ Kylian MbappÃ© (ID {player_id}) â†’ Goals: {total_goals} | Assists: {total_assists}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "futpeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
