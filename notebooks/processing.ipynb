{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c12f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Directorio de trabajo actual: F:\\JCMDataCenter\\Cursos\\Evolve Academy\\Data Scientist IA\\Futpeak\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Establece la raíz del proyecto manualmente\n",
    "project_root = Path(\"F:/JCMDataCenter/Cursos/Evolve Academy/Data Scientist IA/Futpeak\") # sobremesa\n",
    "#project_root = Path(\"C:/Users/juanm/Desktop/FUTPEAK/Futpeak\") # portátil\n",
    "\n",
    "# Cambia el directorio de trabajo actual a esa raíz\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"📁 Directorio de trabajo actual:\", Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637ed5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Step 1 completed → Basic metadata saved at: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# Processing de metadata\n",
    "\n",
    "# Crear csv con id y player name\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths\n",
    "input_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "output_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lines = []\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f if \"fbref.com\" in line]\n",
    "\n",
    "records = []\n",
    "\n",
    "for line in lines:\n",
    "    try:\n",
    "        # === 1. Player ID and Slug\n",
    "        url_match = re.search(r\"https://fbref\\.com/en/players/([a-f0-9]{8})/([^\\s/,]+)\", line)\n",
    "        if not url_match:\n",
    "            continue\n",
    "        player_id = url_match.group(1)\n",
    "        slug = url_match.group(2)\n",
    "        player_name = slug.replace(\"_\", \" \").title()\n",
    "        url_template = url_match.group(0)\n",
    "\n",
    "        # === 2. Full name (text after ID, before next comma)\n",
    "        name_match = re.search(rf\"{player_id},([^,]+)\", line)\n",
    "        full_name = name_match.group(1).strip() if name_match else None\n",
    "\n",
    "        records.append({\n",
    "            \"Player_ID\": player_id,\n",
    "            \"Player_name\": player_name,\n",
    "            \"Full_name\": full_name,\n",
    "            \"Url_template\": url_template\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error on line:\\n{line}\\n→ {e}\")\n",
    "\n",
    "# === Save output\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Step 1 completed → Basic metadata saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855b1165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 2 completado → Full_name actualizado en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 2\n",
    "# Añadir full name válido desde raw y corregir player_name\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para nombres con 3 o más palabras capitalizadas\n",
    "name_pattern = re.compile(\n",
    "    r\"\\b([A-ZÁÉÍÓÚÑ][a-záéíóúñ'’\\-]+(?:\\s+[A-ZÁÉÍÓÚÑ][a-záéíóúñ'’\\-]+){2,})\\b\"\n",
    ")\n",
    "\n",
    "# === Extraer full names desde raw comparando contra player_name\n",
    "clean_full_names = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    player_name = row[\"Player_name\"]\n",
    "\n",
    "    # Buscar línea que contenga el ID del jugador\n",
    "    matching_line = next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")\n",
    "\n",
    "    # Buscar candidato a nombre completo\n",
    "    match = name_pattern.search(matching_line)\n",
    "    candidate = match.group(1) if match else \"\"\n",
    "\n",
    "    player_tokens = player_name.replace(\"-\", \" \").title().split()\n",
    "    full_tokens = candidate.split()\n",
    "\n",
    "    # Validar que al menos 2 palabras coincidan\n",
    "    common = set(p.lower() for p in player_tokens) & set(f.lower() for f in full_tokens)\n",
    "    if candidate and len(common) >= 2:\n",
    "        clean_full_names.append(candidate)\n",
    "    else:\n",
    "        clean_full_names.append(\"\")\n",
    "\n",
    "# === Corregir player_name (sin guiones, capitalizado)\n",
    "df[\"Player_name\"] = df[\"Player_name\"].astype(str).str.replace(\"-\", \" \", regex=False).str.title()\n",
    "\n",
    "# === Insertar nombres completos validados\n",
    "df[\"Full_name\"] = clean_full_names\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 2 completado → Full_name actualizado en: {cleaned_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7cffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 3 completado → Birth_date añadido a: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 3\n",
    "# Añadir fecha de nacimiento\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para fechas en formato YYYY-MM-DD\n",
    "date_pattern = re.compile(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\")\n",
    "\n",
    "# === Buscar fecha de nacimiento para cada jugador en raw_lines\n",
    "birth_dates = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "    \n",
    "    # Buscar la línea que contiene este ID\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    match = date_pattern.search(matching_line)\n",
    "    birth_date = match.group(0) if match else \"\"\n",
    "    birth_dates.append(birth_date)\n",
    "\n",
    "# === Añadir columna al DataFrame\n",
    "df[\"Birth_date\"] = birth_dates\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 3 completado → Birth_date añadido a: {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9922b576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 4 completado → Age añadido a: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 4\n",
    "# Añadir edad (Age)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para edad en formato NN-NNN\n",
    "age_pattern = re.compile(r\"\\b\\d{2}-\\d{3}\\b\")\n",
    "\n",
    "# === Buscar edad para cada jugador en raw_lines\n",
    "ages = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "    \n",
    "    # Buscar línea que contiene el ID\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    match = age_pattern.search(matching_line)\n",
    "    age = match.group(0) if match else \"\"\n",
    "    ages.append(age)\n",
    "\n",
    "# === Añadir columna al DataFrame\n",
    "df[\"Age\"] = ages\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 4 completado → Age añadido a: {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cf5ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 5 completado → Position añadido correctamente a: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 5\n",
    "# Añadir posición (Position)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load existing cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para extraer etiquetas en mayúsculas (ej. DF, MF, CB, etc.)\n",
    "position_pattern = re.compile(r\"\\b([A-Z]{2,})\\b\")\n",
    "\n",
    "positions = []\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar línea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    matches = position_pattern.findall(matching_line)\n",
    "\n",
    "    # Filtrar posibles valores válidos (puedes ajustar lógica aquí si hace falta)\n",
    "    valid = sorted(set(m for m in matches if len(m) >= 2))\n",
    "    \n",
    "    positions.append(\"-\".join(valid) if valid else \"\")\n",
    "\n",
    "# === Añadir al DataFrame\n",
    "df[\"Position\"] = positions\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 5 completado → Position añadido correctamente a: {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07791581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 6 completado → Footed añadido correctamente en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 6\n",
    "# Añadir pierna dominante (Footed)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load current cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para detectar pierna dominante\n",
    "footed_pattern = re.compile(r\"\\b(Right|Left)\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "footed_values = []\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar la línea que contiene el ID del jugador\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "\n",
    "    match = footed_pattern.search(matching_line)\n",
    "    footed = match.group(1).capitalize() if match else \"\"\n",
    "    footed_values.append(footed)\n",
    "\n",
    "# === Añadir columna Footed\n",
    "df[\"Footed\"] = footed_values\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 6 completado → Footed añadido correctamente en: {cleaned_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76edbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 7 completado → Birth_place añadido correctamente en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 7\n",
    "# Añadir lugar de nacimiento (Birth_place)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Load cleaned CSV\n",
    "df = pd.read_csv(cleaned_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Read raw metadata lines (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para extraer 'in City, Country'\n",
    "birthplace_pattern = re.compile(r'\"in ([^\"]+,[^\"]+)\"')\n",
    "\n",
    "birth_places = []\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar línea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "\n",
    "    match = birthplace_pattern.search(matching_line)\n",
    "    place = match.group(1).strip() if match else \"\"\n",
    "    birth_places.append(place)\n",
    "\n",
    "# === Añadir al DataFrame\n",
    "df[\"Birth_place\"] = birth_places\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 7 completado → Birth_place añadido correctamente en: {cleaned_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69dd5f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 8 completado → Nationality añadida correctamente en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 8\n",
    "# Añadir nacionalidad (Nationality)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths\n",
    "metadata_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "teams_path = Path(\"data/meta/World_Cup_Qualification_Teams.csv\")\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "\n",
    "# === Load data\n",
    "df = pd.read_csv(metadata_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "teams_df = pd.read_csv(teams_path, dtype=str, encoding=\"utf-8\")\n",
    "\n",
    "# === Lista de países válidos\n",
    "country_names = set(teams_df[\"National Team\"].dropna().str.strip())\n",
    "\n",
    "# === Leer las líneas originales (sin header)\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = [line.strip() for line in f.readlines()][1:]\n",
    "\n",
    "# === Buscar país para cada jugador\n",
    "nationalities = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar línea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "    \n",
    "    found = next((country for country in country_names if country in matching_line), \"\")\n",
    "    nationalities.append(found)\n",
    "\n",
    "# === Asignar columna y guardar\n",
    "df[\"Nationality\"] = nationalities\n",
    "df.to_csv(metadata_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 8 completado → Nationality añadida correctamente en: {metadata_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a904ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 9 completado → Full_name corregido y Club añadido en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 9\n",
    "# Añadir club (Club) y corregir Full_name con control total\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "df_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Cargar DataFrame existente\n",
    "df = pd.read_csv(df_path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Cargar líneas crudas\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "# === Regex para Full_name con 3+ palabras capitalizadas\n",
    "name_regex = re.compile(\n",
    "    r\"\\b([A-ZÁÉÍÓÚÑ][a-záéíóúñü']+(?:\\s+[A-ZÁÉÍÓÚÑ][a-záéíóúñü']+){2,})\\b\"\n",
    ")\n",
    "\n",
    "# === Procesamiento\n",
    "clean_full_names = []\n",
    "clubs = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar línea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\")\n",
    "\n",
    "    # === Step 1: Full name limpio\n",
    "    name_match = name_regex.search(matching_line)\n",
    "    clean_name = name_match.group(1) if name_match else \"\"\n",
    "    clean_full_names.append(clean_name)\n",
    "\n",
    "    # === Step 2: Club\n",
    "    parts = [p.strip() for p in matching_line.split(\",\") if p.strip()]\n",
    "\n",
    "    known_vals = {\n",
    "        row[\"Player_name\"].lower(),\n",
    "        clean_name.lower(),\n",
    "        row[\"Player_ID\"].lower(),\n",
    "        row[\"Footed\"].lower(),\n",
    "        row[\"Birth_date\"].lower(),\n",
    "        row[\"Age\"].lower(),\n",
    "        row[\"Birth_place\"].lower(),\n",
    "        row[\"Nationality\"].lower(),\n",
    "    }\n",
    "\n",
    "    best_candidate = \"\"\n",
    "    for part in parts:\n",
    "        pl = part.lower()\n",
    "\n",
    "        if (\n",
    "            not part\n",
    "            or \"http\" in pl\n",
    "            or \"footed\" in pl\n",
    "            or \"position\" in pl\n",
    "            or \"in \" in pl\n",
    "            or re.fullmatch(r\"[a-f0-9]{8}\", pl)\n",
    "            or re.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}\", pl)\n",
    "            or re.fullmatch(r\"\\d{2}-\\d{3}\", pl)\n",
    "            or pl in known_vals\n",
    "            or re.fullmatch(r\"[A-Z]{1,3}(-[A-Z]{1,3})+\", part)  # Ej: CM-DM\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Buscar candidato más probable\n",
    "        if re.fullmatch(r\"[A-Z][a-z]+(?: [A-Z][a-z]+)*\", part) and len(part) > len(best_candidate):\n",
    "            best_candidate = part\n",
    "\n",
    "    clubs.append(best_candidate)\n",
    "\n",
    "# === Asignar columnas finales\n",
    "df[\"Full_name\"] = clean_full_names\n",
    "df[\"Club\"] = clubs\n",
    "\n",
    "# === Guardar archivo actualizado\n",
    "df.to_csv(df_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 9 completado → Full_name corregido y Club añadido en: {df_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99110f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paso 10 completado → Clubs corregidos en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Paso 10\n",
    "# Segunda pasada para refinar Club\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths\n",
    "raw_path = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "df_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "\n",
    "# === Cargar DataFrame y raw lines\n",
    "df = pd.read_csv(df_path, dtype=str).fillna(\"\")\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = f.readlines()[1:]\n",
    "\n",
    "clubs_fixed = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    player_id = row[\"Player_ID\"]\n",
    "\n",
    "    # Buscar línea correspondiente\n",
    "    matching_line = next((line for line in raw_lines if player_id in line), \"\").strip().replace('\"', '')\n",
    "    parts = [p.strip() for p in matching_line.split(\",\") if p.strip()]\n",
    "\n",
    "    # Valores ya conocidos para este jugador\n",
    "    known = {\n",
    "        row[\"Player_name\"].lower(),\n",
    "        row[\"Full_name\"].lower(),\n",
    "        row[\"Footed\"].lower(),\n",
    "        row[\"Birth_date\"].lower(),\n",
    "        row[\"Age\"].lower(),\n",
    "        row[\"Birth_place\"].lower(),\n",
    "        row[\"Nationality\"].lower(),\n",
    "        row[\"Position\"].lower(),\n",
    "    }\n",
    "\n",
    "    # Buscar mejor candidato a club\n",
    "    best = \"\"\n",
    "    for p in parts:\n",
    "        pl = p.lower()\n",
    "        if (\n",
    "            not p\n",
    "            or \"http\" in pl\n",
    "            or pl in known\n",
    "            or any(x in pl for x in [\"position\", \"footed\", \"in \"])\n",
    "            or len(p) < 2\n",
    "            or p.isupper()\n",
    "            or p.replace(\"-\", \"\").isupper()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        if p[0].isupper():\n",
    "            best = p  # última candidata válida\n",
    "\n",
    "    clubs_fixed.append(best)\n",
    "\n",
    "df[\"Club\"] = clubs_fixed\n",
    "\n",
    "# === Guardar CSV final con Club corregido\n",
    "df.to_csv(df_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Paso 10 completado → Clubs corregidos en: {df_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8922f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Género inferido automáticamente y guardado en: data\\processed\\cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# === Processing de metadata: Inferir género usando gender-guesser\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "# === Paths\n",
    "csv_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Crear detector\n",
    "detector = gender.Detector(case_sensitive=False)\n",
    "\n",
    "# === Extraer primer nombre\n",
    "df[\"First_name\"] = df[\"Player_name\"].str.strip().str.split().str[0]\n",
    "\n",
    "# === Inferir género usando la librería\n",
    "def normalize_gender(name):\n",
    "    try:\n",
    "        raw = detector.get_gender(name)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "    if raw in [\"male\", \"mostly_male\"]:\n",
    "        return \"male\"\n",
    "    elif raw in [\"female\", \"mostly_female\"]:\n",
    "        return \"female\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"Gender\"] = df[\"First_name\"].apply(normalize_gender)\n",
    "\n",
    "# === Guardar CSV actualizado\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Género inferido automáticamente y guardado en: {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e993fbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Recuento por género:\n",
      "Gender\n",
      "male       14547\n",
      "unknown     2104\n",
      "female       876\n",
      "Name: count, dtype: int64\n",
      "\n",
      "👀 Ejemplos de jugadores con género 'unknown':\n",
      "                    Full_name First_name  \\\n",
      "26                             Lisandro   \n",
      "42                              Joaquin   \n",
      "43        Yamil Rodrigo Asad      Yamil   \n",
      "59   Cristian Nahuel Barrios     Nahuel   \n",
      "101                              Nahuel   \n",
      "151                             Lautaro   \n",
      "157    Carlos Joaquín Correa    Joaquin   \n",
      "170                              Braian   \n",
      "172  Hernán Nicolás Da Campo     Hernan   \n",
      "236       Luis Yamil Garnier      Yamil   \n",
      "\n",
      "                                       Club  \n",
      "26                                LDU Quito  \n",
      "42                                           \n",
      "43                                   Cuiabá  \n",
      "59                         Barracas Central  \n",
      "101                                Talleres  \n",
      "151                        Sportivo Luqueno  \n",
      "157                          Internazionale  \n",
      "170  Central Córdoba de Santiago del Estero  \n",
      "172                              Sport Boys  \n",
      "236                                          \n"
     ]
    }
   ],
   "source": [
    "# === Ver resumen de género\n",
    "print(\"🔍 Recuento por género:\")\n",
    "print(df[\"Gender\"].value_counts(dropna=False))\n",
    "print(\"\\n👀 Ejemplos de jugadores con género 'unknown':\\n\", df[df[\"Gender\"] == \"unknown\"][[\"Full_name\", \"First_name\", \"Club\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db7a066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Yamil Rodrigo Asad → male\n",
      "⚠️ Error con Cristian Nahuel Barrios: Message: invalid session id: session deleted as the browser has closed the connection\n",
      "from disconnected: not connected to DevTools\n",
      "  (Session info: chrome=136.0.7103.114)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00B7FC83+61635]\n",
      "\tGetHandleVerifier [0x00B7FCC4+61700]\n",
      "\t(No symbol) [0x009A05D3]\n",
      "\t(No symbol) [0x0098FE20]\n",
      "\t(No symbol) [0x009ADD1F]\n",
      "\t(No symbol) [0x00A13E8C]\n",
      "\t(No symbol) [0x00A2DF19]\n",
      "\t(No symbol) [0x00A0D096]\n",
      "\t(No symbol) [0x009DC840]\n",
      "\t(No symbol) [0x009DD6A4]\n",
      "\tGetHandleVerifier [0x00E045A3+2701795]\n",
      "\tGetHandleVerifier [0x00DFFD26+2683238]\n",
      "\tGetHandleVerifier [0x00E1AA6E+2793134]\n",
      "\tGetHandleVerifier [0x00B96945+155013]\n",
      "\tGetHandleVerifier [0x00B9D02D+181357]\n",
      "\tGetHandleVerifier [0x00B874D8+92440]\n",
      "\tGetHandleVerifier [0x00B87680+92864]\n",
      "\tGetHandleVerifier [0x00B72070+5296]\n",
      "\tBaseThreadInitThunk [0x74CD5D49+25]\n",
      "\tRtlInitializeExceptionChain [0x76FED03B+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x76FECFC1+561]\n",
      "\n",
      "✅ Cristian Nahuel Barrios → unknown\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgender\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Error general con \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# === Cargar dataset\n",
    "csv_path = Path(\"data/processed/cleaned_metadata.csv\")\n",
    "df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Configurar navegador\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# === Asegurar columna Gender\n",
    "if \"Gender\" not in df.columns:\n",
    "    df[\"Gender\"] = \"unknown\"\n",
    "\n",
    "# === Función de detección con Bing + múltiples bloques\n",
    "def infer_gender_bing(full_name):\n",
    "    try:\n",
    "        query = f\"{full_name} futbolista\"\n",
    "        bing_url = f\"https://www.bing.com/search?q={query.replace(' ', '+')}\"\n",
    "        driver.get(bing_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        snippets = []\n",
    "\n",
    "        # Seleccionamos múltiples bloques relevantes\n",
    "        selectors = [\n",
    "            \"div.b_entityTP\",  # panel destacado\n",
    "            \"div.b_context\",\n",
    "            \"div.b_caption\",\n",
    "            \"div.b_algo\",\n",
    "            \"div.b_snippet\",\n",
    "        ]\n",
    "\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                el = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                snippets.append(el.text.lower())\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        full_text = \" \".join(snippets)\n",
    "\n",
    "        if \"es una futbolista\" in full_text:\n",
    "            return \"female\"\n",
    "        elif \"es un futbolista\" in full_text:\n",
    "            return \"male\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error con {full_name}: {e}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "# === Iterar por unknowns\n",
    "for i, row in df[df[\"Gender\"] == \"unknown\"].iterrows():\n",
    "    full_name = row[\"Full_name\"]\n",
    "    if not isinstance(full_name, str) or not full_name.strip():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        gender = infer_gender_bing(full_name)\n",
    "        df.at[i, \"Gender\"] = gender\n",
    "        print(f\"✅ {full_name} → {gender}\")\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "        time.sleep(1.5)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error general con {full_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "print(\"🎯 Completado. Géneros actualizados en el CSV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250bed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Final cleaned CSV saved at: data\\processed\\cleaned_matchlogs.csv | Rows: 1947093\n"
     ]
    }
   ],
   "source": [
    "# Processing completo y final\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === File paths\n",
    "input_path = Path(\"data/raw/top_10_countries_matchlogs_filtered.csv\")\n",
    "output_path = Path(\"data/processed/cleaned_matchlogs.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Step 1: Load raw CSV\n",
    "df = pd.read_csv(input_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Step 2: Normalize player_name formatting\n",
    "df[\"player_name\"] = df[\"player_name\"].str.replace(\"_\", \" \", regex=False).str.title()\n",
    "\n",
    "# === Step 3: Rename columns\n",
    "rename_dict = {\n",
    "    \"player_name\": \"Player_name\",\n",
    "    \"player_id\": \"Player_ID\",\n",
    "    \"season\": \"Seasons\",\n",
    "    \"Date\": \"Date\", \"Day\": \"Day\", \"Comp\": \"Competition\", \"Round\": \"Round\", \"Venue\": \"Home_Away\",\n",
    "    \"Result\": \"Result\", \"Squad\": \"Player_team\", \"Opponent\": \"Rival_team\", \"Start\": \"Start\",\n",
    "    \"Pos\": \"Position\", \"Min\": \"Minutes\", \"Gls\": \"Goals\", \"Ast\": \"Assists\", \"PK\": \"Penalty_kick\",\n",
    "    \"PKatt\": \"Penalty_kick_att\", \"Sh\": \"Shots\", \"SoT\": \"Shots_on_target\", \"CrdY\": \"Yellow_cards\",\n",
    "    \"CrdR\": \"Red_cards\", \"Fls\": \"Fouls_committed\", \"Fld\": \"Fouls_drawn\", \"Off\": \"Offsides\",\n",
    "    \"Crs\": \"Crosses\", \"TklW\": \"Tackles_won\", \"Int\": \"Interceptions\", \"OG\": \"Own_goals\",\n",
    "    \"PKwon\": \"Penaltys_won\", \"PKcon\": \"Penaltys_conceded\", \"Touches\": \"Touches\", \"Tkl\": \"Tackles\",\n",
    "    \"Blocks\": \"Blocks\", \"xG\": \"xG\", \"npxG\": \"non_penalty_xG\", \"xAG\": \"x_assisted_G\",\n",
    "    \"SCA\": \"Shot_creating_actions\", \"GCA\": \"Goal_creating_actions\", \"Cmp\": \"Passes_completed\",\n",
    "    \"Att\": \"Passes_att\", \"Cmp%\": \"Percent_passes\", \"PrgP\": \"Progressive_passes\",\n",
    "    \"Carries\": \"Feet_control\", \"PrgC\": \"Progressive_control\", \"Succ\": \"Dribling_suc\"\n",
    "}\n",
    "df.rename(columns={k: v for k, v in rename_dict.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# === Step 4: Remove unwanted columns\n",
    "for col in [\"Match Report\", \"season\", \"player_name\", \"player_id\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# === Step 5: Clean rows (required fields must be present)\n",
    "df = df[df[\"Player_name\"].notna() & df[\"Player_ID\"].notna() & df[\"Seasons\"].notna()]\n",
    "if \"Date\" in df.columns:\n",
    "    df = df[df[\"Date\"].notna()]\n",
    "\n",
    "# === Step 6: Remove rows where the player didn’t play\n",
    "if \"Position\" in df.columns:\n",
    "    df = df[df[\"Position\"] != \"On matchday squad, but did not play\"]\n",
    "\n",
    "# ✅ Step 6.5: Drop rows where all values are empty (except core fields)\n",
    "non_core = [col for col in df.columns if col not in [\"Player_name\", \"Player_ID\", \"Seasons\"]]\n",
    "df = df[df[non_core].apply(lambda row: any(cell.strip() for cell in row), axis=1)]\n",
    "\n",
    "# === Step 7: Remove duplicate games (player_id + date)\n",
    "if \"Date\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"Player_ID\", \"Date\"])\n",
    "\n",
    "# === Step 8: Clean up team names by removing country codes\n",
    "for col in [\"Player_team\", \"Rival_team\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.replace(r\"^[a-z]{2,3}\\s+\", \"\", regex=True)\n",
    "\n",
    "# === Step 9: Reorder columns\n",
    "core = [\"Player_name\", \"Player_ID\", \"Seasons\"]\n",
    "rest = [c for c in df.columns if c not in core]\n",
    "df = df[core + rest]\n",
    "\n",
    "# === Step 10: Save\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"🎯 Final cleaned CSV saved at: {output_path} | Rows: {len(df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Final cleaned CSV saved at: data\\processed\\future_stars_cleaned_matchlogs.csv | Rows: 1053\n"
     ]
    }
   ],
   "source": [
    "# Processing completo y final JUGADORES JÓVENES\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === File paths\n",
    "input_path = Path(\"data/raw/top_10_countries_matchlogs_young_players.csv\")\n",
    "output_path = Path(\"data/processed/future_stars_cleaned_matchlogs.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Step 1: Load raw CSV\n",
    "df = pd.read_csv(input_path, dtype=str, encoding=\"utf-8\").fillna(\"\")\n",
    "\n",
    "# === Step 2: Normalize player_name formatting\n",
    "df[\"player_name\"] = df[\"player_name\"].str.replace(\"_\", \" \", regex=False).str.title()\n",
    "\n",
    "# === Step 3: Rename columns\n",
    "rename_dict = {\n",
    "    \"player_name\": \"Player_name\",\n",
    "    \"player_id\": \"Player_ID\",\n",
    "    \"season\": \"Seasons\",\n",
    "    \"Date\": \"Date\", \"Day\": \"Day\", \"Comp\": \"Competition\", \"Round\": \"Round\", \"Venue\": \"Home_Away\",\n",
    "    \"Result\": \"Result\", \"Squad\": \"Player_team\", \"Opponent\": \"Rival_team\", \"Start\": \"Start\",\n",
    "    \"Pos\": \"Position\", \"Min\": \"Minutes\", \"Gls\": \"Goals\", \"Ast\": \"Assists\", \"PK\": \"Penalty_kick\",\n",
    "    \"PKatt\": \"Penalty_kick_att\", \"Sh\": \"Shots\", \"SoT\": \"Shots_on_target\", \"CrdY\": \"Yellow_cards\",\n",
    "    \"CrdR\": \"Red_cards\", \"Fls\": \"Fouls_committed\", \"Fld\": \"Fouls_drawn\", \"Off\": \"Offsides\",\n",
    "    \"Crs\": \"Crosses\", \"TklW\": \"Tackles_won\", \"Int\": \"Interceptions\", \"OG\": \"Own_goals\",\n",
    "    \"PKwon\": \"Penaltys_won\", \"PKcon\": \"Penaltys_conceded\", \"Touches\": \"Touches\", \"Tkl\": \"Tackles\",\n",
    "    \"Blocks\": \"Blocks\", \"xG\": \"xG\", \"npxG\": \"non_penalty_xG\", \"xAG\": \"x_assisted_G\",\n",
    "    \"SCA\": \"Shot_creating_actions\", \"GCA\": \"Goal_creating_actions\", \"Cmp\": \"Passes_completed\",\n",
    "    \"Att\": \"Passes_att\", \"Cmp%\": \"Percent_passes\", \"PrgP\": \"Progressive_passes\",\n",
    "    \"Carries\": \"Feet_control\", \"PrgC\": \"Progressive_control\", \"Succ\": \"Dribling_suc\"\n",
    "}\n",
    "df.rename(columns={k: v for k, v in rename_dict.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# === Step 4: Remove unwanted columns\n",
    "for col in [\"Match Report\", \"season\", \"player_name\", \"player_id\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# === Step 5: Clean rows (required fields must be present)\n",
    "df = df[df[\"Player_name\"].notna() & df[\"Player_ID\"].notna() & df[\"Seasons\"].notna()]\n",
    "if \"Date\" in df.columns:\n",
    "    df = df[df[\"Date\"].notna()]\n",
    "\n",
    "# === Step 6: Remove rows where the player didn’t play\n",
    "if \"Position\" in df.columns:\n",
    "    df = df[df[\"Position\"] != \"On matchday squad, but did not play\"]\n",
    "\n",
    "# ✅ Step 6.5: Drop rows where all values are empty (except core fields)\n",
    "non_core = [col for col in df.columns if col not in [\"Player_name\", \"Player_ID\", \"Seasons\"]]\n",
    "df = df[df[non_core].apply(lambda row: any(cell.strip() for cell in row), axis=1)]\n",
    "\n",
    "# === Step 7: Remove duplicate games (player_id + date)\n",
    "if \"Date\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"Player_ID\", \"Date\"])\n",
    "\n",
    "# === Step 8: Clean up team names by removing country codes\n",
    "for col in [\"Player_team\", \"Rival_team\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.replace(r\"^[a-z]{2,3}\\s+\", \"\", regex=True)\n",
    "\n",
    "# === Step 9: Reorder columns\n",
    "core = [\"Player_name\", \"Player_ID\", \"Seasons\"]\n",
    "rest = [c for c in df.columns if c not in core]\n",
    "df = df[core + rest]\n",
    "\n",
    "# === Step 10: Save\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"🎯 Final cleaned CSV saved at: {output_path} | Rows: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed44c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def process_metadata_file(raw_path: Path, cleaned_path: Path, teams_path: Path = Path(\"data/meta/World_Cup_Qualification_Teams.csv\")):\n",
    "    raw_lines = [line.strip() for line in raw_path.read_text(encoding=\"utf-8\").splitlines()[1:]]\n",
    "\n",
    "    # === Paso 1: ID, slug, nombre base\n",
    "    records = []\n",
    "    for line in raw_lines:\n",
    "        url_match = re.search(r\"https://fbref\\.com/en/players/([a-f0-9]{8})/([^\\s/,]+)\", line)\n",
    "        if not url_match:\n",
    "            continue\n",
    "        player_id = url_match.group(1)\n",
    "        slug = url_match.group(2)\n",
    "        player_name = slug.replace(\"_\", \" \").title()\n",
    "        url_template = url_match.group(0)\n",
    "\n",
    "        name_match = re.search(rf\"{player_id},([^,]+)\", line)\n",
    "        full_name = name_match.group(1).strip() if name_match else \"\"\n",
    "\n",
    "        records.append({\n",
    "            \"Player_ID\": player_id,\n",
    "            \"Player_name\": player_name,\n",
    "            \"Full_name\": full_name,\n",
    "            \"Url_template\": url_template\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records).fillna(\"\")\n",
    "\n",
    "    # === Paso 2: Validar Full_name\n",
    "    name_pattern = re.compile(r\"\\b([A-ZÁÉÍÓÚÑ][a-záéíóúñü'’\\-]+(?:\\s+[A-ZÁÉÍÓÚÑ][a-záéíóúñü'’\\-]+){2,})\\b\")\n",
    "    clean_full_names = []\n",
    "    for _, row in df.iterrows():\n",
    "        match_line = next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")\n",
    "        match = name_pattern.search(match_line)\n",
    "        candidate = match.group(1) if match else \"\"\n",
    "\n",
    "        player_tokens = row[\"Player_name\"].replace(\"-\", \" \").title().split()\n",
    "        full_tokens = candidate.split()\n",
    "        common = set(p.lower() for p in player_tokens) & set(f.lower() for f in full_tokens)\n",
    "\n",
    "        clean_full_names.append(candidate if candidate and len(common) >= 2 else \"\")\n",
    "    df[\"Player_name\"] = df[\"Player_name\"].str.replace(\"-\", \" \", regex=False).str.title()\n",
    "    df[\"Full_name\"] = clean_full_names\n",
    "\n",
    "    # === Paso 3: Birth_date\n",
    "    date_pattern = re.compile(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\")\n",
    "    df[\"Birth_date\"] = [\n",
    "        date_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")).group(0)\n",
    "        if date_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 4: Age\n",
    "    age_pattern = re.compile(r\"\\b\\d{2}-\\d{3}\\b\")\n",
    "    df[\"Age\"] = [\n",
    "        age_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")).group(0)\n",
    "        if age_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 5: Position\n",
    "    pos_pattern = re.compile(r\"\\b([A-Z]{2,})\\b\")\n",
    "    df[\"Position\"] = [\n",
    "        \"-\".join(sorted(set(m for m in pos_pattern.findall(\n",
    "            next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")\n",
    "        ) if len(m) >= 2))) or \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 6: Footed\n",
    "    footed_pattern = re.compile(r\"\\b(Right|Left)\\b\", flags=re.IGNORECASE)\n",
    "    df[\"Footed\"] = [\n",
    "        (footed_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) or re.match(\"\", \"\")).group(0).capitalize()\n",
    "        if footed_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 7: Birth_place\n",
    "    birth_place_pattern = re.compile(r'\"in ([^\"]+,[^\"]+)\"')\n",
    "    df[\"Birth_place\"] = [\n",
    "        birth_place_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")).group(1).strip()\n",
    "        if birth_place_pattern.search(next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")) else \"\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 8: Nationality\n",
    "    teams_df = pd.read_csv(teams_path, dtype=str)\n",
    "    countries = set(teams_df[\"National Team\"].dropna().str.strip())\n",
    "\n",
    "    df[\"Nationality\"] = [\n",
    "        next((country for country in countries if country in next((line for line in raw_lines if row[\"Player_ID\"] in line), \"\")), \"\")\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # === Paso 9-10: Club (refinado)\n",
    "    clubs = []\n",
    "    for _, row in df.iterrows():\n",
    "        line = next((l for l in raw_lines if row[\"Player_ID\"] in l), \"\").replace('\"', '')\n",
    "        parts = [p.strip() for p in line.split(\",\") if p.strip()]\n",
    "        known = {str(row[k]).lower() for k in [\"Player_name\", \"Full_name\", \"Footed\", \"Birth_date\", \"Age\", \"Birth_place\", \"Nationality\", \"Position\"]}\n",
    "        best = \"\"\n",
    "        for p in parts:\n",
    "            pl = p.lower()\n",
    "            if (\n",
    "                not p or \"http\" in pl or pl in known or len(p) < 2 or\n",
    "                \"position\" in pl or \"footed\" in pl or \"in \" in pl or\n",
    "                p.isupper() or p.replace(\"-\", \"\").isupper()\n",
    "            ):\n",
    "                continue\n",
    "            if p[0].isupper():\n",
    "                best = p\n",
    "        clubs.append(best)\n",
    "    df[\"Club\"] = clubs\n",
    "\n",
    "    # === Paso FINAL: Asignar Gender = male\n",
    "    df[\"Gender\"] = \"male\"\n",
    "\n",
    "    # === Guardar CSV final\n",
    "    cleaned_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(cleaned_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ Metadata procesada y guardada en: {cleaned_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14976380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadata procesada y guardada en: data\\processed\\future_stars_cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "raw_path = Path(\"data/raw/future_stars_raw_metadata.csv\")\n",
    "cleaned_path = Path(\"data/processed/future_stars_cleaned_metadata.csv\")\n",
    "\n",
    "df_cleaned = process_metadata_file(raw_path, cleaned_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c24956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Marcos Acuña (ID: 81442ecb)\n",
      "   Total matches played: 431\n",
      "   ➤ With Argentina: 59\n",
      "   ➤ With Clubs: 372\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Load cleaned matchlogs\n",
    "path = Path(\"data/processed/cleaned_matchlogs.csv\")\n",
    "df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Filtrar por jugador\n",
    "player_id = \"81442ecb\"\n",
    "df_acuna = df[df[\"Player_ID\"] == player_id].copy()\n",
    "\n",
    "# === Filtrar partidos jugados (Min > 0)\n",
    "df_acuna[\"Minutes\"] = pd.to_numeric(df_acuna[\"Minutes\"], errors=\"coerce\").fillna(0)\n",
    "df_played = df_acuna[df_acuna[\"Minutes\"] > 0]\n",
    "\n",
    "# === Contar\n",
    "total_matches = len(df_played)\n",
    "national_team_matches = len(df_played[df_played[\"Player_team\"] == \"Argentina\"])\n",
    "club_matches = total_matches - national_team_matches\n",
    "\n",
    "print(f\"🎯 Marcos Acuña (ID: {player_id})\")\n",
    "print(f\"   Total matches played: {total_matches}\")\n",
    "print(f\"   ➤ With Argentina: {national_team_matches}\")\n",
    "print(f\"   ➤ With Clubs: {club_matches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f96c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚽ Marcos Acuña (ID 81442ecb) → Goals: 30 | Assists: 57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Load cleaned matchlogs\n",
    "path = Path(\"data/processed/cleaned_matchlogs.csv\")\n",
    "df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "\n",
    "# === Filtrar por Player_ID\n",
    "player_id = \"81442ecb\"\n",
    "df_acuna = df[df[\"Player_ID\"] == player_id].copy()\n",
    "\n",
    "# Convertir columnas numéricas\n",
    "df_acuna[\"Goals\"] = pd.to_numeric(df_acuna[\"Goals\"], errors=\"coerce\").fillna(0)\n",
    "df_acuna[\"Assists\"] = pd.to_numeric(df_acuna[\"Assists\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# === Calcular totales\n",
    "total_goals = int(df_acuna[\"Goals\"].sum())\n",
    "total_assists = int(df_acuna[\"Assists\"].sum())\n",
    "\n",
    "print(f\"⚽ Marcos Acuña (ID {player_id}) → Goals: {total_goals} | Assists: {total_assists}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72f1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚽ Kylian Mbappé (ID 42fd9c7f) → Goals: 0 | Assists: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV limpio\n",
    "df = pd.read_csv(\"data/processed/cleaned_matchlogs.csv\")\n",
    "\n",
    "# === Filtrar por Player_ID\n",
    "player_id = \"42fd9c7f\"\n",
    "df_mbappe = df[df[\"Player_ID\"] == player_id].copy()\n",
    "\n",
    "# Convertir columnas numéricas\n",
    "df_mbappe[\"Goals\"] = pd.to_numeric(df_mbappe[\"Goals\"], errors=\"coerce\").fillna(0)\n",
    "df_mbappe[\"Assists\"] = pd.to_numeric(df_mbappe[\"Assists\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# === Calcular totales\n",
    "total_goals = int(df_mbappe[\"Goals\"].sum())\n",
    "total_assists = int(df_mbappe[\"Assists\"].sum())\n",
    "\n",
    "\n",
    "print(f\"⚽ Kylian Mbappé (ID {player_id}) → Goals: {total_goals} | Assists: {total_assists}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "futpeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
