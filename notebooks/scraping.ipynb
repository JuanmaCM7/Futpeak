{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da073d5",
   "metadata": {},
   "source": [
    "## Voy pegando aqu√≠ abajo el c√≥digo √∫til"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6affa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directorio de trabajo actual: F:\\JCMDataCenter\\Cursos\\Evolve Academy\\Data Scientist IA\\Futpeak\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Establece la ra√≠z del proyecto manualmente\n",
    "project_root = Path(\"F:/JCMDataCenter/Cursos/Evolve Academy/Data Scientist IA/Futpeak\") # sobremesa\n",
    "#project_root = Path(\"C:/Users/juanm/Desktop/FUTPEAK/Futpeak\") # port√°til\n",
    "\n",
    "# Cambia el directorio de trabajo actual a esa ra√≠z\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"üìÅ Directorio de trabajo actual:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef11c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_urls = {\n",
    "    \"Argentina\": \"https://fbref.com/en/country/players/ARG/Argentina-Football-Players\",\n",
    "    \"Brazil\": \"https://fbref.com/en/country/players/BRA/Brazil-Football-Players\",\n",
    "    \"France\": \"https://fbref.com/en/country/players/FRA/France-Football-Players\",\n",
    "    \"Spain\": \"https://fbref.com/en/country/players/ESP/Spain-Football-Players\",\n",
    "    \"England\": \"https://fbref.com/en/country/players/ENG/England-Football-Players\",\n",
    "    \"Germany\": \"https://fbref.com/en/country/players/GER/Germany-Football-Players\",\n",
    "    \"Italy\": \"https://fbref.com/en/country/players/ITA/Italy-Football-Players\",\n",
    "    \"Belgium\": \"https://fbref.com/en/country/players/BEL/Belgium-Football-Players\",\n",
    "    \"Netherlands\": \"https://fbref.com/en/country/players/NED/Netherlands-Football-Players\",\n",
    "    \"Portugal\": \"https://fbref.com/en/country/players/POR/Portugal-Football-Players\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1081a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping de jugadores de top 10 pa√≠ses FIFA para crear el yaml\n",
    "\n",
    "import yaml\n",
    "import time\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CHROME_PATH = \"C:/Windows/System32/chromedriver.exe\"\n",
    "BASE_URL = \"https://fbref.com\"\n",
    "OUTPUT_YAML = Path(\"data/meta/top_10_countries_players.yaml\")\n",
    "OUTPUT_YAML.parent.mkdir(parents=True, exist_ok=True)\n",
    "WAIT_PER_PAGE = 10\n",
    "WAIT_BETWEEN_COUNTRIES = 15\n",
    "\n",
    "# === SETUP SELENIUM (visible) ===\n",
    "options = Options()\n",
    "# Comment out to see browser:\n",
    "# options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(CHROME_PATH), options=options)\n",
    "\n",
    "# === INIT YAML clean ===\n",
    "with open(OUTPUT_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump([], f)\n",
    "\n",
    "# === SCRAPE ALL COUNTRIES ===\n",
    "total_players = 0\n",
    "consecutive_fails = 0\n",
    "\n",
    "for country, url in country_urls.items():\n",
    "    print(f\"\\nüåç Opening: {country}...\")\n",
    "    driver.get(url)\n",
    "    print(f\"‚è≥ Waiting {WAIT_PER_PAGE}s to load or solve CAPTCHA...\")\n",
    "    time.sleep(WAIT_PER_PAGE)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Dynamically find player section\n",
    "    section = None\n",
    "    for candidate in soup.select(\"div.section_content\"):\n",
    "        p_tags = candidate.find_all(\"p\")\n",
    "        valid = [\n",
    "            p for p in p_tags\n",
    "            if p.find(\"a\", href=True) and \"/en/players/\" in p.find(\"a\")[\"href\"]\n",
    "        ]\n",
    "        if len(valid) > 10:\n",
    "            section = candidate\n",
    "            break\n",
    "\n",
    "    if not section:\n",
    "        print(f\"‚ö†Ô∏è Could not find player block for {country}. Skipping.\")\n",
    "        consecutive_fails += 1\n",
    "        if consecutive_fails >= 3:\n",
    "            print(\"‚õî Too many skips. Stopping early.\")\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    consecutive_fails = 0\n",
    "    player_tags = section.find_all(\"p\")\n",
    "    print(f\"üîç Found {len(player_tags)} players in {country}\")\n",
    "\n",
    "    players = []\n",
    "\n",
    "    for tag in player_tags:\n",
    "        a = tag.find(\"a\")\n",
    "        if not a or not a.get(\"href\"):\n",
    "            continue\n",
    "\n",
    "        name_raw = a.text.strip()\n",
    "        href = a[\"href\"].strip()\n",
    "        full_url = BASE_URL + href\n",
    "\n",
    "        try:\n",
    "            player_id = href.split(\"/\")[3]\n",
    "        except IndexError:\n",
    "            player_id = None\n",
    "\n",
    "        trailing = tag.get_text(separator=\" \").replace(name_raw, \"\").strip()\n",
    "        parts = [p.strip() for p in trailing.split(\"¬∑\")]\n",
    "\n",
    "        players.append({\n",
    "            \"id\": player_id,\n",
    "            \"name\": name_raw.replace(\" \", \"_\").lower(),\n",
    "            \"display_name\": name_raw,\n",
    "            \"url\": full_url,\n",
    "            \"years\": parts[0] if len(parts) > 0 else None,\n",
    "            \"position\": parts[1] if len(parts) > 1 else None,\n",
    "            \"clubs\": parts[2] if len(parts) > 2 else None,\n",
    "            \"country\": country\n",
    "        })\n",
    "\n",
    "    # Save incrementally\n",
    "    with open(OUTPUT_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "        current_data = yaml.safe_load(f) or []\n",
    "\n",
    "    current_data.extend(players)\n",
    "\n",
    "    with open(OUTPUT_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.dump(current_data, f, allow_unicode=True)\n",
    "\n",
    "    total_players += len(players)\n",
    "    print(f\"‚úÖ {country} done. Total so far: {total_players}\")\n",
    "    time.sleep(WAIT_BETWEEN_COUNTRIES)\n",
    "\n",
    "driver.quit()\n",
    "print(f\"\\nüíæ Saved all players to: {OUTPUT_YAML}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all players from 2014 and with 10+ years career\n",
    "\n",
    "# üì¶ Imports\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "input_path = Path(\"data/meta/top_10_countries_players.yaml\")\n",
    "output_path = Path(\"data/meta/top_10_countries_players_filtered.yaml\")\n",
    "\n",
    "# === Load YAML ===\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_players = yaml.safe_load(f)\n",
    "\n",
    "# === Filter players\n",
    "filtered_players = []\n",
    "\n",
    "for p in all_players:\n",
    "    years = p.get(\"years\", \"\")\n",
    "    if not years or \"-\" not in years:\n",
    "        continue\n",
    "    try:\n",
    "        start, end = years.split(\"-\")\n",
    "        start_year = int(start)\n",
    "        end_year = int(end)\n",
    "        if start_year >= 2014 and (end_year - start_year + 1) >= 10:\n",
    "            filtered_players.append(p)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# === Save result\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump(filtered_players, f, allow_unicode=True)\n",
    "\n",
    "print(f\"‚úÖ Total filtered players: {len(filtered_players)}\")\n",
    "print(f\"üìÑ Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo scraping matchlogs fbref para seguir desde un jugador con un ID espec√≠fico\n",
    "\n",
    "# üì¶ Imports\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CHROME_PATH = \"C:/Windows/System32/chromedriver.exe\"\n",
    "INPUT_YAML = Path(\"data/meta/top_10_countries_players_filtered.yaml\")\n",
    "OUTPUT_CSV = Path(\"data/raw/top_10_countries_matchlogs_filtered.csv\")\n",
    "RESUME_FROM_ID = \"42fd9c7f\" # Kylian Mbapp√©\n",
    "SLEEP_TIME = 8\n",
    "\n",
    "# === Load YAML players ===\n",
    "with open(INPUT_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_players = yaml.safe_load(f)\n",
    "\n",
    "# === Find resume point\n",
    "resume_index = 0\n",
    "for i, player in enumerate(all_players):\n",
    "    if player.get(\"id\") == RESUME_FROM_ID:\n",
    "        resume_index = i\n",
    "        break\n",
    "remaining_players = all_players[resume_index:]\n",
    "print(f\"üîÅ Resuming from index {resume_index}: {remaining_players[0]['name']}\")\n",
    "\n",
    "# === Setup Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(CHROME_PATH), options=options)\n",
    "\n",
    "# === Check if CSV exists\n",
    "output_exists = OUTPUT_CSV.exists()\n",
    "if not output_exists:\n",
    "    pd.DataFrame().to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# === Scraping from RESUME point onward ===\n",
    "for player in remaining_players:\n",
    "    player_id = player.get(\"id\")\n",
    "    player_name = player.get(\"name\")\n",
    "    profile_url = player.get(\"url\")\n",
    "    if not player_id or not player_name or not profile_url:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüßç Scraping {player_name} | ID: {player_id}\")\n",
    "\n",
    "    try:\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # === Extract summary match log seasons\n",
    "        summary_section = soup.find(\"div\", id=\"inner_nav\")\n",
    "        matchlog_links = []\n",
    "        if summary_section:\n",
    "            matchlog_links = {\n",
    "                a[\"href\"] for a in summary_section.find_all(\"a\", href=True)\n",
    "                if \"/matchlogs/\" in a[\"href\"] and \"Match-Logs\" in a[\"href\"] and \"summary\" in a[\"href\"].lower()\n",
    "        }\n",
    "\n",
    "\n",
    "        if not matchlog_links:\n",
    "            print(\"   ‚ö†Ô∏è No Match Logs (Summary) seasons found.\")\n",
    "            continue\n",
    "\n",
    "        player_rows = []\n",
    "\n",
    "        for rel_url in matchlog_links:\n",
    "            full_url = \"https://fbref.com\" + rel_url\n",
    "            season = rel_url.split(\"/matchlogs/\")[1].split(\"/\")[0]\n",
    "            print(f\"   üîç {season} ‚Äî {full_url}\")\n",
    "\n",
    "            try:\n",
    "                driver.get(full_url)\n",
    "                time.sleep(SLEEP_TIME)\n",
    "                sub_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                table = sub_soup.find(\"table\", {\"id\": \"matchlogs_all\"})\n",
    "\n",
    "                if table:\n",
    "                    header_rows = table.find(\"thead\").find_all(\"tr\")\n",
    "                    final_header = header_rows[-1]\n",
    "                    columns = [th.text.strip() for th in final_header.find_all(\"th\")]\n",
    "\n",
    "                    for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "                        if \"class\" in row.attrs and \"thead\" in row[\"class\"]:\n",
    "                            continue\n",
    "                        cells = row.find_all([\"th\", \"td\"])\n",
    "                        values = [cell.text.strip() for cell in cells]\n",
    "                        row_data = dict(zip(columns, values))\n",
    "                        row_data[\"season\"] = season\n",
    "                        row_data[\"player_name\"] = player_name\n",
    "                        row_data[\"player_id\"] = player_id\n",
    "                        player_rows.append(row_data)\n",
    "                else:\n",
    "                    print(\"      ‚ö†Ô∏è No matchlogs_all table in season.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Error processing season {season}: {e}\")\n",
    "\n",
    "        if player_rows:\n",
    "            df_player = pd.DataFrame(player_rows)\n",
    "            df_player.to_csv(OUTPUT_CSV, mode=\"a\", index=False, header=not output_exists)\n",
    "            output_exists = True\n",
    "            print(f\"   ‚úÖ {len(df_player)} rows added for {player_name}\")\n",
    "        else:\n",
    "            print(f\"   üö´ No data scraped for {player_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {player_name}: {e}\")\n",
    "\n",
    "driver.quit()\n",
    "print(f\"\\nüì¶ Done. Appended new match logs to: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780668bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping metadata players filtered\n",
    "\n",
    "# üì¶ Imports\n",
    "import yaml\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# === Paths ===\n",
    "YAML_PATH = \"data/meta/top_10_countries_players_filtered.yaml\"\n",
    "OUTPUT_FILE = Path(\"data/raw/top_10_countries_players_filtered_raw_metadata.csv\")\n",
    "CHROME_PATH = \"C:/Windows/System32/chromedriver.exe\"\n",
    "\n",
    "# === Load YAML\n",
    "with open(YAML_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    players = yaml.safe_load(f)\n",
    "\n",
    "# === Set the last scraped URL (for continuation)\n",
    "# Leave it empty \"\" to scrape from the beginning\n",
    "last_scraped_url = \"\"\n",
    "\n",
    "# === Find starting point\n",
    "start_index = 0  # By default start from 0\n",
    "\n",
    "if last_scraped_url:\n",
    "    for idx, player in enumerate(players):\n",
    "        if player[\"url_template\"] == last_scraped_url:\n",
    "            start_index = idx + 1  # Start AFTER the last scraped player\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå last_scraped_url not found in male_players.yaml!\")\n",
    "\n",
    "players = players[start_index:]  # Only keep players after last scraped\n",
    "\n",
    "print(f\"üöÄ Starting scraping from index {start_index} ({players[0]['name']})\")\n",
    "\n",
    "# === Setup Selenium\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")  # Optional: hide browser if you want\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "service = Service(executable_path=CHROME_PATH)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# === Metadata extraction\n",
    "def extract_metadata(driver):\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    meta = soup.find(\"div\", id=\"meta\")\n",
    "    if not meta:\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        full_name = meta.find(\"p\").text.strip()\n",
    "    except:\n",
    "        full_name = None\n",
    "\n",
    "    position = footed = None\n",
    "    try:\n",
    "        pos_block = meta.find(\"strong\", string=\"Position:\").parent\n",
    "        if pos_block:\n",
    "            text = pos_block.get_text(separator=\"|\")\n",
    "            parts = text.split(\"|\")\n",
    "            position = parts[1].strip() if len(parts) > 1 else None\n",
    "            footed = parts[3].strip() if \"Footed:\" in text and len(parts) > 3 else None\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    birth_date = age = birth_place = None\n",
    "    try:\n",
    "        birth_tag = meta.find(\"strong\", string=\"Born:\")\n",
    "        if birth_tag:\n",
    "            birth_block = birth_tag.parent\n",
    "            date_span = birth_block.find(\"span\")\n",
    "            if date_span:\n",
    "                birth_date = date_span.get(\"data-birth\")\n",
    "                if not birth_date:\n",
    "                    raw_text = date_span.text.strip()\n",
    "                    try:\n",
    "                        birth_date = pd.to_datetime(raw_text).strftime(\"%Y-%m-%d\")\n",
    "                    except:\n",
    "                        birth_date = None\n",
    "\n",
    "            nobr = birth_block.find(\"nobr\")\n",
    "            if nobr:\n",
    "                raw_age = nobr.text\n",
    "                match = re.search(r\"Age:\\s*([\\d\\-]+)\", raw_age)\n",
    "                age = match.group(1) if match else None\n",
    "\n",
    "            birth_place_span = nobr.find_next(\"span\") if nobr else None\n",
    "            if birth_place_span:\n",
    "                birth_place = birth_place_span.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    nationality = None\n",
    "    try:\n",
    "        nat_tag = meta.find(\"strong\", string=\"National Team:\")\n",
    "        if nat_tag:\n",
    "            nationality = nat_tag.find_next(\"a\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if not nationality:\n",
    "        try:\n",
    "            citizen_tag = meta.find(\"strong\", string=\"Citizenship:\")\n",
    "            if citizen_tag:\n",
    "                nationality = citizen_tag.find_next(\"a\").text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    club = None\n",
    "    try:\n",
    "        club_tag = meta.find(\"strong\", string=\"Club:\")\n",
    "        if club_tag:\n",
    "            club = club_tag.find_next(\"a\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        \"full_name\": full_name,\n",
    "        \"position\": position,\n",
    "        \"footed\": footed,\n",
    "        \"birth_date\": birth_date,\n",
    "        \"age\": age,\n",
    "        \"birth_place\": birth_place,\n",
    "        \"nationality\": nationality,\n",
    "        \"club\": club\n",
    "    }\n",
    "\n",
    "# === Create output file if not exists\n",
    "if not OUTPUT_FILE.exists():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pd.DataFrame(columns=[\n",
    "        \"player_name\", \"url_template\", \"full_name\", \"position\", \"footed\",\n",
    "        \"birth_date\", \"age\", \"birth_place\", \"nationality\", \"club\"\n",
    "    ]).to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "# === Main loop\n",
    "for i, player in enumerate(players, start=start_index + 1):\n",
    "    player_name = player[\"name\"]\n",
    "    player_url = player[\"url_template\"]\n",
    "\n",
    "    print(f\"\\nüîç [{i}] Scraping: {player_url}\")\n",
    "\n",
    "    retries = 0\n",
    "    max_retries = 3\n",
    "    success = False\n",
    "\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            driver.get(player_url)\n",
    "            sleep_time = random.uniform(8, 12)\n",
    "            print(f\"‚è≥ Waiting {sleep_time:.2f} seconds after loading...\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "            data = extract_metadata(driver)\n",
    "            if not data:\n",
    "                print(f\"‚ö†Ô∏è No metadata found for {player_name}\")\n",
    "                break\n",
    "\n",
    "            data[\"player_name\"] = player_name\n",
    "            data[\"url_template\"] = player_url\n",
    "\n",
    "            pd.DataFrame([data]).to_csv(OUTPUT_FILE, mode=\"a\", header=False, index=False)\n",
    "            print(f\"‚úÖ Saved metadata for {player_name}\")\n",
    "            success = True\n",
    "\n",
    "        except WebDriverException as e:\n",
    "            if \"ERR_INTERNET_DISCONNECTED\" in str(e):\n",
    "                retries += 1\n",
    "                print(f\"‚ö†Ô∏è Internet disconnected. Retrying ({retries}/{max_retries})...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"‚ùå WebDriver error: {e}\")\n",
    "                break\n",
    "\n",
    "driver.quit()\n",
    "print(f\"\\nüíæ Done! Full metadata saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç 2022-2023 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2022-2023/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2023-2024 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2023-2024/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2024-2025 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2024-2025/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2019-2020 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2019-2020/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2018-2019 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2018-2019/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2016-2017 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2016-2017/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2017-2018 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2017-2018/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2021-2022 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2021-2022/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2015-2016 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2015-2016/summary/Kylian-Mbappe-Match-Logs\n",
      "üîç 2020-2021 ‚Äî https://fbref.com/en/players/42fd9c7f/matchlogs/2020-2021/summary/Kylian-Mbappe-Match-Logs\n",
      "\n",
      "‚úÖ Guardado: 576 filas en data\\debug\\mbappe_matchlogs_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# Test scraping Mbapp√©\n",
    "\n",
    "# üì¶ Imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CHROME_PATH = \"C:/Windows/System32/chromedriver.exe\"  # Ajusta si hace falta\n",
    "OUTPUT_CSV = Path(\"data/debug/mbappe_matchlogs_raw.csv\")\n",
    "SLEEP_TIME = 8\n",
    "\n",
    "# === Mbapp√© Info\n",
    "player_id = \"42fd9c7f\"\n",
    "player_name = \"kylian_mbappe\"\n",
    "profile_url = \"https://fbref.com/en/players/42fd9c7f/matchlogs/\"\n",
    "\n",
    "# === Selenium Setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(CHROME_PATH), options=options)\n",
    "\n",
    "# === Scrape Mbapp√©\n",
    "driver.get(profile_url)\n",
    "time.sleep(SLEEP_TIME)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "summary_section = soup.find(\"div\", id=\"inner_nav\")\n",
    "matchlog_links = []\n",
    "if summary_section:\n",
    "    matchlog_links = {\n",
    "        a[\"href\"] for a in summary_section.find_all(\"a\", href=True)\n",
    "        if \"/matchlogs/\" in a[\"href\"]\n",
    "        and \"Match-Logs\" in a[\"href\"]\n",
    "        and \"summary\" in a[\"href\"].lower() \n",
    "    }\n",
    "\n",
    "if not matchlog_links:\n",
    "    print(\"‚ö†Ô∏è No Match Logs (Summary) seasons found.\")\n",
    "else:\n",
    "    player_rows = []\n",
    "\n",
    "    for rel_url in matchlog_links:\n",
    "        full_url = \"https://fbref.com\" + rel_url\n",
    "        season = rel_url.split(\"/matchlogs/\")[1].split(\"/\")[0]\n",
    "        print(f\"üîç {season} ‚Äî {full_url}\")\n",
    "\n",
    "        try:\n",
    "            driver.get(full_url)\n",
    "            time.sleep(SLEEP_TIME)\n",
    "            sub_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            table = sub_soup.find(\"table\", {\"id\": \"matchlogs_all\"})\n",
    "\n",
    "            if table:\n",
    "                header_rows = table.find(\"thead\").find_all(\"tr\")\n",
    "                final_header = header_rows[-1]\n",
    "                columns = [th.text.strip() for th in final_header.find_all(\"th\")]\n",
    "\n",
    "                for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "                    if \"class\" in row.attrs and \"thead\" in row[\"class\"]:\n",
    "                        continue\n",
    "                    cells = row.find_all([\"th\", \"td\"])\n",
    "                    values = [cell.text.strip() for cell in cells]\n",
    "                    row_data = dict(zip(columns, values))\n",
    "\n",
    "                    # ‚úÖ A√±adir datos clave al principio\n",
    "                    row_data_ordered = {\n",
    "                        \"player_name\": player_name,\n",
    "                        \"player_id\": player_id,\n",
    "                        \"season\": season\n",
    "                    }\n",
    "                    row_data_ordered.update(row_data)\n",
    "                    player_rows.append(row_data_ordered)\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è No matchlogs_all table found.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error processing season {season}: {e}\")\n",
    "\n",
    "    if player_rows:\n",
    "        df_mbappe = pd.DataFrame(player_rows)\n",
    "        OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # ‚úÖ Asegurar orden de columnas\n",
    "        ordered_cols = [\"player_name\", \"player_id\", \"season\"]\n",
    "        remaining_cols = [col for col in df_mbappe.columns if col not in ordered_cols]\n",
    "        df_mbappe = df_mbappe[ordered_cols + remaining_cols]\n",
    "\n",
    "        df_mbappe.to_csv(OUTPUT_CSV, index=False)\n",
    "        print(f\"\\n‚úÖ Guardado: {len(df_mbappe)} filas en {OUTPUT_CSV}\")\n",
    "    else:\n",
    "        print(\"üö´ No se extrajeron datos para Mbapp√©.\")\n",
    "\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a23013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Resuming from index 20: facundo_altamirano\n",
      "\n",
      "üßç Scraping facundo_altamirano | ID: 84d5fd29\n",
      "   üîç 2021 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2021/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2022 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2022/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2024/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2015/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2016-2017/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2018-2019/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2023 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2023/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2018 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2018/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2017-2018 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2017-2018/summary/Facundo-Altamirano-Match-Logs\n",
      "   üîç 2019-2020 ‚Äî https://fbref.com/en/players/84d5fd29/matchlogs/2019-2020/summary/Facundo-Altamirano-Match-Logs\n",
      "   ‚úÖ 281 rows added for facundo_altamirano\n",
      "\n",
      "üßç Scraping juan_alvacete | ID: 55d260d7\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/55d260d7/matchlogs/2016/summary/Juan-Alvacete-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/55d260d7/matchlogs/2015/summary/Juan-Alvacete-Match-Logs\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/55d260d7/matchlogs/2024/summary/Juan-Alvacete-Match-Logs\n",
      "   üîç 2023 ‚Äî https://fbref.com/en/players/55d260d7/matchlogs/2023/summary/Juan-Alvacete-Match-Logs\n",
      "   ‚úÖ 67 rows added for juan_alvacete\n",
      "\n",
      "üßç Scraping fabricio_alvarenga | ID: a38a572a\n",
      "   üîç 2018 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2018/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2021-2022 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2021-2022/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2022-2023 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2022-2023/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2020-2021 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2020-2021/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2016-2017/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2015/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2023-2024 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2023-2024/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2017-2018 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2017-2018/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/a38a572a/matchlogs/2016/summary/Fabricio-Alvarenga-Match-Logs\n",
      "   ‚úÖ 169 rows added for fabricio_alvarenga\n",
      "\n",
      "üßç Scraping fabio_√°lvarez | ID: 2aae3ff2\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2024/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2019 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2019/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2018-2019/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2023 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2023/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2017 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2017/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2017-2018 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2017-2018/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2016-2017/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2015/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2018 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2018/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2021-2022 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2021-2022/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2020-2021 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2020-2021/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2019-2020 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2019-2020/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2016/summary/Fabio-Alvarez-Match-Logs\n",
      "   üîç 2022 ‚Äî https://fbref.com/en/players/2aae3ff2/matchlogs/2022/summary/Fabio-Alvarez-Match-Logs\n",
      "   ‚úÖ 459 rows added for fabio_√°lvarez\n",
      "\n",
      "üßç Scraping federico_√°lvarez | ID: 32a9f0f0\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2015/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2016-2017/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2016/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2018-2019/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2020-2021 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2020-2021/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2022-2023 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2022-2023/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2023-2024 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2023-2024/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2021-2022 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2021-2022/summary/Federico-Alvarez-Match-Logs\n",
      "   üîç 2024-2025 ‚Äî https://fbref.com/en/players/32a9f0f0/matchlogs/2024-2025/summary/Federico-Alvarez-Match-Logs\n",
      "   ‚úÖ 224 rows added for federico_√°lvarez\n",
      "\n",
      "üßç Scraping leonel_√°lvarez | ID: 1fb139b1\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/1fb139b1/matchlogs/2024/summary/Leonel-Alvarez-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/1fb139b1/matchlogs/2016-2017/summary/Leonel-Alvarez-Match-Logs\n",
      "   üîç 2017 ‚Äî https://fbref.com/en/players/1fb139b1/matchlogs/2017/summary/Leonel-Alvarez-Match-Logs\n",
      "   üîç 2025 ‚Äî https://fbref.com/en/players/1fb139b1/matchlogs/2025/summary/Leonel-Alvarez-Match-Logs\n",
      "   ‚úÖ 49 rows added for leonel_√°lvarez\n",
      "\n",
      "üßç Scraping lisandro_alzugaray | ID: 4f7e4f00\n",
      "   üîç 2020 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2020/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2021 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2021/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2022 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2022/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2016-2017/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2023 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2023/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2019-2020 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2019-2020/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2018-2019/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2025 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2025/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/4f7e4f00/matchlogs/2024/summary/Lisandro-Alzugaray-Match-Logs\n",
      "   ‚úÖ 234 rows added for lisandro_alzugaray\n",
      "\n",
      "üßç Scraping joel_amoroso | ID: 4b5fff76\n",
      "   üîç 2017-2018 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2017-2018/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2022 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2022/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2019 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2019/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2025 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2025/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2016-2017/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2024/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2016/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2020 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2020/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2015/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2021 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2021/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2018-2019/summary/Joel-Amoroso-Match-Logs\n",
      "   üîç 2023 ‚Äî https://fbref.com/en/players/4b5fff76/matchlogs/2023/summary/Joel-Amoroso-Match-Logs\n",
      "   ‚úÖ 329 rows added for joel_amoroso\n",
      "\n",
      "üßç Scraping nicol√°s_andereggen | ID: 3eeb8fa4\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2016-2017/summary/Nicolas-Andereggen-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2016/summary/Nicolas-Andereggen-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2015/summary/Nicolas-Andereggen-Match-Logs\n",
      "   üîç 2017-2018 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2017-2018/summary/Nicolas-Andereggen-Match-Logs\n",
      "   üîç 2021 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2021/summary/Nicolas-Andereggen-Match-Logs\n",
      "   üîç 2020 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2020/summary/Nicolas-Andereggen-Match-Logs\n",
      "   üîç 2023-2024 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2023-2024/summary/Nicolas-Andereggen-Match-Logs\n",
      "      ‚ö†Ô∏è No table found.\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/3eeb8fa4/matchlogs/2018-2019/summary/Nicolas-Andereggen-Match-Logs\n",
      "   ‚úÖ 49 rows added for nicol√°s_andereggen\n",
      "\n",
      "üßç Scraping brian_andrada | ID: 7d4c074a\n",
      "   üîç 2024 ‚Äî https://fbref.com/en/players/7d4c074a/matchlogs/2024/summary/Brian-Andrada-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/7d4c074a/matchlogs/2016/summary/Brian-Andrada-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/7d4c074a/matchlogs/2015/summary/Brian-Andrada-Match-Logs\n",
      "   ‚úÖ 47 rows added for brian_andrada\n",
      "\n",
      "üßç Scraping esteban_andrada | ID: 775d365e\n",
      "   üîç 2019-2020 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2019-2020/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2018-2019 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2018-2019/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2017-2018 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2017-2018/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2021-2022 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2021-2022/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2015 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2015/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2016-2017 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2016-2017/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2023-2024 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2023-2024/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç nat_tm ‚Äî https://fbref.com/en/players/775d365e/matchlogs/nat_tm/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2018 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2018/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2019 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2019/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2021 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2021/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2022-2023 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2022-2023/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2016 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2016/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2020 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2020/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2014 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2014/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2024-2025 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2024-2025/summary/Esteban-Andrada-Match-Logs\n",
      "   üîç 2017 ‚Äî https://fbref.com/en/players/775d365e/matchlogs/2017/summary/Esteban-Andrada-Match-Logs\n",
      "   ‚úÖ 536 rows added for esteban_andrada\n",
      "\n",
      "üßç Scraping federico_andrada | ID: c997824a\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müßç Scraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(SLEEP_TIME)\n\u001b[0;32m     77\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:454\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m    tab.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:427\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    425\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m    145\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\miniconda3\\envs\\futpeak\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DEFINITIVO, 100% REAL NO FAKE\n",
    "\n",
    "# Scraping matchlogs FBref desde YAML (alineado y reanudable)\n",
    "\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CHROME_PATH = \"C:/Windows/System32/chromedriver.exe\"\n",
    "INPUT_YAML = Path(\"data/meta/top_10_countries_players_filtered.yaml\")\n",
    "OUTPUT_CSV = Path(\"data/raw/top_10_countries_matchlogs_filtered.csv\")\n",
    "RESUME_FROM_ID = \"c997824a\"  # Cambia si quieres reanudar desde otro jugador\n",
    "SLEEP_TIME = 8\n",
    "LIMIT_PLAYERS = None  # Usa None para recorrer todos los jugadores\n",
    "\n",
    "# === Column definitions\n",
    "stat_columns = [\n",
    "    \"Date\", \"Day\", \"Comp\", \"Round\", \"Venue\", \"Result\", \"Squad\", \"Opponent\", \"Start\",\n",
    "    \"Pos\", \"Min\", \"Gls\", \"Ast\", \"PK\", \"PKatt\", \"Sh\", \"SoT\", \"CrdY\", \"CrdR\", \"Fls\", \"Fld\", \"Off\",\n",
    "    \"Crs\", \"TklW\", \"Int\", \"OG\", \"PKwon\", \"PKcon\", \"Touches\", \"Tkl\", \"Blocks\", \"xG\", \"npxG\", \"xAG\",\n",
    "    \"SCA\", \"GCA\", \"Cmp\", \"Att\", \"Cmp%\", \"PrgP\", \"Carries\", \"PrgC\", \"Succ\"\n",
    "]\n",
    "final_columns = [\"player_name\", \"player_id\", \"season\"] + stat_columns\n",
    "\n",
    "# === Load YAML\n",
    "with open(INPUT_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_players = yaml.safe_load(f)\n",
    "\n",
    "# === Resume from specific ID\n",
    "resume_index = 0\n",
    "for i, player in enumerate(all_players):\n",
    "    if player.get(\"id\") == RESUME_FROM_ID:\n",
    "        resume_index = i\n",
    "        break\n",
    "remaining_players = all_players[resume_index:]\n",
    "if LIMIT_PLAYERS:\n",
    "    remaining_players = remaining_players[:LIMIT_PLAYERS]\n",
    "\n",
    "print(f\"üîÅ Resuming from index {resume_index}: {remaining_players[0]['name']}\")\n",
    "\n",
    "# === Selenium setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(CHROME_PATH), options=options)\n",
    "\n",
    "# === Check if CSV exists and whether it is empty\n",
    "output_exists = OUTPUT_CSV.exists()\n",
    "if output_exists:\n",
    "    try:\n",
    "        existing_df = pd.read_csv(OUTPUT_CSV, dtype=str)\n",
    "        output_exists = not existing_df.empty\n",
    "    except Exception:\n",
    "        output_exists = False\n",
    "\n",
    "if not output_exists:\n",
    "    pd.DataFrame(columns=final_columns).to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# === Scraping loop\n",
    "for player in remaining_players:\n",
    "    player_id = player.get(\"id\")\n",
    "    player_name = player.get(\"name\")\n",
    "    profile_url = player.get(\"url\")\n",
    "    if not player_id or not player_name or not profile_url:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüßç Scraping {player_name} | ID: {player_id}\")\n",
    "    try:\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # === Get matchlog links (all seasons)\n",
    "        summary_section = soup.find(\"div\", id=\"inner_nav\")\n",
    "        matchlog_links = {\n",
    "            a[\"href\"] for a in summary_section.find_all(\"a\", href=True)\n",
    "            if \"/matchlogs/\" in a[\"href\"] and \"Match-Logs\" in a[\"href\"] and \"summary\" in a[\"href\"].lower()\n",
    "        } if summary_section else set()\n",
    "\n",
    "        if not matchlog_links:\n",
    "            print(\"   ‚ö†Ô∏è No match logs found.\")\n",
    "            continue\n",
    "\n",
    "        player_rows = []\n",
    "\n",
    "        for rel_url in matchlog_links:\n",
    "            full_url = \"https://fbref.com\" + rel_url\n",
    "            season = rel_url.split(\"/matchlogs/\")[1].split(\"/\")[0]\n",
    "            print(f\"   üîç {season} ‚Äî {full_url}\")\n",
    "\n",
    "            try:\n",
    "                driver.get(full_url)\n",
    "                time.sleep(SLEEP_TIME)\n",
    "                sub_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                table = sub_soup.find(\"table\", {\"id\": \"matchlogs_all\"})\n",
    "\n",
    "                if table:\n",
    "                    header = table.find(\"thead\").find_all(\"tr\")[-1]\n",
    "                    columns = [th.text.strip() for th in header.find_all(\"th\")]\n",
    "\n",
    "                    for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "                        if \"class\" in row.attrs and \"thead\" in row[\"class\"]:\n",
    "                            continue\n",
    "                        cells = row.find_all([\"th\", \"td\"])\n",
    "                        values = [cell.text.strip() for cell in cells]\n",
    "                        raw_data = dict(zip(columns, values))\n",
    "\n",
    "                        aligned = {\n",
    "                            \"player_name\": player_name,\n",
    "                            \"player_id\": player_id,\n",
    "                            \"season\": season\n",
    "                        }\n",
    "                        for col in stat_columns:\n",
    "                            aligned[col] = raw_data.get(col, \"\")\n",
    "                        player_rows.append(aligned)\n",
    "                else:\n",
    "                    print(\"      ‚ö†Ô∏è No table found.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Error scraping season {season}: {e}\")\n",
    "\n",
    "        if player_rows:\n",
    "            df_player = pd.DataFrame(player_rows)[final_columns]\n",
    "            df_player.to_csv(OUTPUT_CSV, mode=\"a\", index=False, header=not output_exists)\n",
    "            output_exists = True\n",
    "            print(f\"   ‚úÖ {len(df_player)} rows added for {player_name}\")\n",
    "        else:\n",
    "            print(f\"   üö´ No data for {player_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {player_name}: {e}\")\n",
    "\n",
    "driver.quit()\n",
    "print(f\"\\nüì¶ Done. Appended logs to: {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "futpeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
